date of comment,main comment,comment,depth,PTR Sentiment (Comment),Flair Outlook,Flair Score
,"Hi, I am a founder who is trying to build ""Google for Financial Research"" start out from equity research. Today, I'd like to share my thoughts on how the past few years has been for AI, the current status, and finally the future. I do not know everything but wish to learn new things. So, I would love to get honest thoughts on my view --- and also my product if you're interested :) Value Chain First, you can view the LM value chain similar to the computer value chain. Foundation model providers like OpenAI and Anthropic are similar to semiconductor designers(fabless; e.g., Nvidia, Qualcomm). They design the models. Performance is everything. Cloud companies like Azure, AWS, and GCP are like semiconductor manufacturers(e.g., TSMC, Samsung Electronics). They provide training resources for actually making production-grade models. Cost and reliability is everything. Finally, newly born application companies or existing ones those who are harnessing this technology is like computer companies(e.g., Apple, Dell). They don't need to know what's under the hood, as it's abstracted. User experience is everything. Past Yeah so, over the past few years. GPT. Boom! That's how it the world started to become interesting (and inflating). GPT-2 was sensational to tech guys. GPT-3 comes out, that becomes history. GPT-3.5? GPT-4. ... You get the point. OpenAI has been leading this industry ever since its emergence into the mass market. Although many competitors like Anthropic and Google has joined the league, and they also perform very well, it is OpenAI that is dominating its presence in the arena. I think Altman's plan is to make OpenAI's models to be the go-to-model for intelligent systems, and he is succeeding very well. Fyi, I am really not a big fan of Sam so don't judge me wrong. Present Now, the present. As you all know, the only real winner in this market is right now Nvidia and PaaS companies. No doubt on this. All the companies building foundation models like GPT, Claude, or Mistral is falling apart. Either suffering from wrong operation(e.g., Stability) or poor financial health. The global surge of these new companies trying to construct a new tech infrastructure has only lead to those who provide 1) datasets, 2) GPU server instances, 3) actual GPUs, 4) and energy. But in order for this waterfall to sustain, the foundation model providers need to actually generate profit to keep the cycle going. Unfortunately, infrastructures make money from people(or companies) trying to build applications. Well, applications ... Hmm ... As a founder who is actually building one, the truth is, the only two product that I've seen engineers applying to their systems is OpenAI's gpt-4o and Anthropic's Claude-3.5 Sonnet. Of course, there are open-source models that you can host by yourself, but that's just not essential for those who are trying to build AI applications. Even large software companies like Microsoft and Notion solely depend on gpt-4o. So, the sad thing is that most of these FM providers will die either by financially perishing or getting acquired by larger infrastructures like AWS, Azure, and GCP. Future I am really excited about this and have some thoughts on this. I will get back to you guys on this if you found this post to be interesting. In the mean time, feel free to ask me questions and let's discuss about... anything! Cheers.","Past:People got excited because ChatGPT seemed smart.Present:People have realized ChatGPT is just verbose predictive text, nobody wants to pay for it, it's getting shoved in our faces by tech platforms so they can claim people use it. The only people pretending to be excited about it are those with sunk costs, a trend all too familiar from Crypto, NFTs, and ""The Metaverse""Future:This bubble also pops.I came up with an easy way to explain the philosophical flaw in LLM's today, which prevents them from doing the things boosters always claim they'll be able to do when they ""fix hallucinations"": ""It's hallucinating even when it's right"".",0,nan,nan,nan
,"Hi, I am a founder who is trying to build ""Google for Financial Research"" start out from equity research. Today, I'd like to share my thoughts on how the past few years has been for AI, the current status, and finally the future. I do not know everything but wish to learn new things. So, I would love to get honest thoughts on my view --- and also my product if you're interested :) Value Chain First, you can view the LM value chain similar to the computer value chain. Foundation model providers like OpenAI and Anthropic are similar to semiconductor designers(fabless; e.g., Nvidia, Qualcomm). They design the models. Performance is everything. Cloud companies like Azure, AWS, and GCP are like semiconductor manufacturers(e.g., TSMC, Samsung Electronics). They provide training resources for actually making production-grade models. Cost and reliability is everything. Finally, newly born application companies or existing ones those who are harnessing this technology is like computer companies(e.g., Apple, Dell). They don't need to know what's under the hood, as it's abstracted. User experience is everything. Past Yeah so, over the past few years. GPT. Boom! That's how it the world started to become interesting (and inflating). GPT-2 was sensational to tech guys. GPT-3 comes out, that becomes history. GPT-3.5? GPT-4. ... You get the point. OpenAI has been leading this industry ever since its emergence into the mass market. Although many competitors like Anthropic and Google has joined the league, and they also perform very well, it is OpenAI that is dominating its presence in the arena. I think Altman's plan is to make OpenAI's models to be the go-to-model for intelligent systems, and he is succeeding very well. Fyi, I am really not a big fan of Sam so don't judge me wrong. Present Now, the present. As you all know, the only real winner in this market is right now Nvidia and PaaS companies. No doubt on this. All the companies building foundation models like GPT, Claude, or Mistral is falling apart. Either suffering from wrong operation(e.g., Stability) or poor financial health. The global surge of these new companies trying to construct a new tech infrastructure has only lead to those who provide 1) datasets, 2) GPU server instances, 3) actual GPUs, 4) and energy. But in order for this waterfall to sustain, the foundation model providers need to actually generate profit to keep the cycle going. Unfortunately, infrastructures make money from people(or companies) trying to build applications. Well, applications ... Hmm ... As a founder who is actually building one, the truth is, the only two product that I've seen engineers applying to their systems is OpenAI's gpt-4o and Anthropic's Claude-3.5 Sonnet. Of course, there are open-source models that you can host by yourself, but that's just not essential for those who are trying to build AI applications. Even large software companies like Microsoft and Notion solely depend on gpt-4o. So, the sad thing is that most of these FM providers will die either by financially perishing or getting acquired by larger infrastructures like AWS, Azure, and GCP. Future I am really excited about this and have some thoughts on this. I will get back to you guys on this if you found this post to be interesting. In the mean time, feel free to ask me questions and let's discuss about... anything! Cheers.","I totally agree with your point on auto regressive text generation via prediction. And yes this bubble will pop. Also, I didn't quite get your last words regarding hallucinations. Could you explain more a bit?",1,nan,nan,nan
,"Hi, I am a founder who is trying to build ""Google for Financial Research"" start out from equity research. Today, I'd like to share my thoughts on how the past few years has been for AI, the current status, and finally the future. I do not know everything but wish to learn new things. So, I would love to get honest thoughts on my view --- and also my product if you're interested :) Value Chain First, you can view the LM value chain similar to the computer value chain. Foundation model providers like OpenAI and Anthropic are similar to semiconductor designers(fabless; e.g., Nvidia, Qualcomm). They design the models. Performance is everything. Cloud companies like Azure, AWS, and GCP are like semiconductor manufacturers(e.g., TSMC, Samsung Electronics). They provide training resources for actually making production-grade models. Cost and reliability is everything. Finally, newly born application companies or existing ones those who are harnessing this technology is like computer companies(e.g., Apple, Dell). They don't need to know what's under the hood, as it's abstracted. User experience is everything. Past Yeah so, over the past few years. GPT. Boom! That's how it the world started to become interesting (and inflating). GPT-2 was sensational to tech guys. GPT-3 comes out, that becomes history. GPT-3.5? GPT-4. ... You get the point. OpenAI has been leading this industry ever since its emergence into the mass market. Although many competitors like Anthropic and Google has joined the league, and they also perform very well, it is OpenAI that is dominating its presence in the arena. I think Altman's plan is to make OpenAI's models to be the go-to-model for intelligent systems, and he is succeeding very well. Fyi, I am really not a big fan of Sam so don't judge me wrong. Present Now, the present. As you all know, the only real winner in this market is right now Nvidia and PaaS companies. No doubt on this. All the companies building foundation models like GPT, Claude, or Mistral is falling apart. Either suffering from wrong operation(e.g., Stability) or poor financial health. The global surge of these new companies trying to construct a new tech infrastructure has only lead to those who provide 1) datasets, 2) GPU server instances, 3) actual GPUs, 4) and energy. But in order for this waterfall to sustain, the foundation model providers need to actually generate profit to keep the cycle going. Unfortunately, infrastructures make money from people(or companies) trying to build applications. Well, applications ... Hmm ... As a founder who is actually building one, the truth is, the only two product that I've seen engineers applying to their systems is OpenAI's gpt-4o and Anthropic's Claude-3.5 Sonnet. Of course, there are open-source models that you can host by yourself, but that's just not essential for those who are trying to build AI applications. Even large software companies like Microsoft and Notion solely depend on gpt-4o. So, the sad thing is that most of these FM providers will die either by financially perishing or getting acquired by larger infrastructures like AWS, Azure, and GCP. Future I am really excited about this and have some thoughts on this. I will get back to you guys on this if you found this post to be interesting. In the mean time, feel free to ask me questions and let's discuss about... anything! Cheers.","Basically, people who promote chatbots as ""AI"" talk about correct information that the chatbots provide as if it's stuff that they ""know"", while reserving the term ""hallucination"" for when the information is wrong.Having made this artificial dichotomy, the only thing necessary in order to create a machine that does what they claim ""AI"" can do is to ""reduce hallucinations"".But this is a totally post-hoc distinction that can only be made by a person capable of determining truth through some non-chatbot means.There's no difference in how correct and incorrect information is generated. It's all just probabalistic text prediction.It works well enough when you ask questions whose answers are likely baked into the training data. Like if I ask ""is a weasel a mammal"" I expect all chatbots to get it right because their training data is full of ""a weasel is a mammal"". But this isn't the type of higher-level thinking they're being advertised as being capable of, and there's an obvious attempt to avoid having discussions like these and just pretend that everything can be solved with more GPU's, more energy, more subsidies, more stolen data, etc.",2,nan,nan,nan
,"Hi, I am a founder who is trying to build ""Google for Financial Research"" start out from equity research. Today, I'd like to share my thoughts on how the past few years has been for AI, the current status, and finally the future. I do not know everything but wish to learn new things. So, I would love to get honest thoughts on my view --- and also my product if you're interested :) Value Chain First, you can view the LM value chain similar to the computer value chain. Foundation model providers like OpenAI and Anthropic are similar to semiconductor designers(fabless; e.g., Nvidia, Qualcomm). They design the models. Performance is everything. Cloud companies like Azure, AWS, and GCP are like semiconductor manufacturers(e.g., TSMC, Samsung Electronics). They provide training resources for actually making production-grade models. Cost and reliability is everything. Finally, newly born application companies or existing ones those who are harnessing this technology is like computer companies(e.g., Apple, Dell). They don't need to know what's under the hood, as it's abstracted. User experience is everything. Past Yeah so, over the past few years. GPT. Boom! That's how it the world started to become interesting (and inflating). GPT-2 was sensational to tech guys. GPT-3 comes out, that becomes history. GPT-3.5? GPT-4. ... You get the point. OpenAI has been leading this industry ever since its emergence into the mass market. Although many competitors like Anthropic and Google has joined the league, and they also perform very well, it is OpenAI that is dominating its presence in the arena. I think Altman's plan is to make OpenAI's models to be the go-to-model for intelligent systems, and he is succeeding very well. Fyi, I am really not a big fan of Sam so don't judge me wrong. Present Now, the present. As you all know, the only real winner in this market is right now Nvidia and PaaS companies. No doubt on this. All the companies building foundation models like GPT, Claude, or Mistral is falling apart. Either suffering from wrong operation(e.g., Stability) or poor financial health. The global surge of these new companies trying to construct a new tech infrastructure has only lead to those who provide 1) datasets, 2) GPU server instances, 3) actual GPUs, 4) and energy. But in order for this waterfall to sustain, the foundation model providers need to actually generate profit to keep the cycle going. Unfortunately, infrastructures make money from people(or companies) trying to build applications. Well, applications ... Hmm ... As a founder who is actually building one, the truth is, the only two product that I've seen engineers applying to their systems is OpenAI's gpt-4o and Anthropic's Claude-3.5 Sonnet. Of course, there are open-source models that you can host by yourself, but that's just not essential for those who are trying to build AI applications. Even large software companies like Microsoft and Notion solely depend on gpt-4o. So, the sad thing is that most of these FM providers will die either by financially perishing or getting acquired by larger infrastructures like AWS, Azure, and GCP. Future I am really excited about this and have some thoughts on this. I will get back to you guys on this if you found this post to be interesting. In the mean time, feel free to ask me questions and let's discuss about... anything! Cheers.","The exciting part of LLMs though, is that they've shown ways to create new user experiences. People will have different experiences because of the ""reasoning"" characteristics --- though yes it is just a global approximation. Still, it's awesome.",1,nan,nan,nan
,"Hi, I am a founder who is trying to build ""Google for Financial Research"" start out from equity research. Today, I'd like to share my thoughts on how the past few years has been for AI, the current status, and finally the future. I do not know everything but wish to learn new things. So, I would love to get honest thoughts on my view --- and also my product if you're interested :) Value Chain First, you can view the LM value chain similar to the computer value chain. Foundation model providers like OpenAI and Anthropic are similar to semiconductor designers(fabless; e.g., Nvidia, Qualcomm). They design the models. Performance is everything. Cloud companies like Azure, AWS, and GCP are like semiconductor manufacturers(e.g., TSMC, Samsung Electronics). They provide training resources for actually making production-grade models. Cost and reliability is everything. Finally, newly born application companies or existing ones those who are harnessing this technology is like computer companies(e.g., Apple, Dell). They don't need to know what's under the hood, as it's abstracted. User experience is everything. Past Yeah so, over the past few years. GPT. Boom! That's how it the world started to become interesting (and inflating). GPT-2 was sensational to tech guys. GPT-3 comes out, that becomes history. GPT-3.5? GPT-4. ... You get the point. OpenAI has been leading this industry ever since its emergence into the mass market. Although many competitors like Anthropic and Google has joined the league, and they also perform very well, it is OpenAI that is dominating its presence in the arena. I think Altman's plan is to make OpenAI's models to be the go-to-model for intelligent systems, and he is succeeding very well. Fyi, I am really not a big fan of Sam so don't judge me wrong. Present Now, the present. As you all know, the only real winner in this market is right now Nvidia and PaaS companies. No doubt on this. All the companies building foundation models like GPT, Claude, or Mistral is falling apart. Either suffering from wrong operation(e.g., Stability) or poor financial health. The global surge of these new companies trying to construct a new tech infrastructure has only lead to those who provide 1) datasets, 2) GPU server instances, 3) actual GPUs, 4) and energy. But in order for this waterfall to sustain, the foundation model providers need to actually generate profit to keep the cycle going. Unfortunately, infrastructures make money from people(or companies) trying to build applications. Well, applications ... Hmm ... As a founder who is actually building one, the truth is, the only two product that I've seen engineers applying to their systems is OpenAI's gpt-4o and Anthropic's Claude-3.5 Sonnet. Of course, there are open-source models that you can host by yourself, but that's just not essential for those who are trying to build AI applications. Even large software companies like Microsoft and Notion solely depend on gpt-4o. So, the sad thing is that most of these FM providers will die either by financially perishing or getting acquired by larger infrastructures like AWS, Azure, and GCP. Future I am really excited about this and have some thoughts on this. I will get back to you guys on this if you found this post to be interesting. In the mean time, feel free to ask me questions and let's discuss about... anything! Cheers.","No, itâ€™s been more annoying than a real person because at least they occasionally can leave the script.",2,nan,nan,nan
,"Hi, I am a founder who is trying to build ""Google for Financial Research"" start out from equity research. Today, I'd like to share my thoughts on how the past few years has been for AI, the current status, and finally the future. I do not know everything but wish to learn new things. So, I would love to get honest thoughts on my view --- and also my product if you're interested :) Value Chain First, you can view the LM value chain similar to the computer value chain. Foundation model providers like OpenAI and Anthropic are similar to semiconductor designers(fabless; e.g., Nvidia, Qualcomm). They design the models. Performance is everything. Cloud companies like Azure, AWS, and GCP are like semiconductor manufacturers(e.g., TSMC, Samsung Electronics). They provide training resources for actually making production-grade models. Cost and reliability is everything. Finally, newly born application companies or existing ones those who are harnessing this technology is like computer companies(e.g., Apple, Dell). They don't need to know what's under the hood, as it's abstracted. User experience is everything. Past Yeah so, over the past few years. GPT. Boom! That's how it the world started to become interesting (and inflating). GPT-2 was sensational to tech guys. GPT-3 comes out, that becomes history. GPT-3.5? GPT-4. ... You get the point. OpenAI has been leading this industry ever since its emergence into the mass market. Although many competitors like Anthropic and Google has joined the league, and they also perform very well, it is OpenAI that is dominating its presence in the arena. I think Altman's plan is to make OpenAI's models to be the go-to-model for intelligent systems, and he is succeeding very well. Fyi, I am really not a big fan of Sam so don't judge me wrong. Present Now, the present. As you all know, the only real winner in this market is right now Nvidia and PaaS companies. No doubt on this. All the companies building foundation models like GPT, Claude, or Mistral is falling apart. Either suffering from wrong operation(e.g., Stability) or poor financial health. The global surge of these new companies trying to construct a new tech infrastructure has only lead to those who provide 1) datasets, 2) GPU server instances, 3) actual GPUs, 4) and energy. But in order for this waterfall to sustain, the foundation model providers need to actually generate profit to keep the cycle going. Unfortunately, infrastructures make money from people(or companies) trying to build applications. Well, applications ... Hmm ... As a founder who is actually building one, the truth is, the only two product that I've seen engineers applying to their systems is OpenAI's gpt-4o and Anthropic's Claude-3.5 Sonnet. Of course, there are open-source models that you can host by yourself, but that's just not essential for those who are trying to build AI applications. Even large software companies like Microsoft and Notion solely depend on gpt-4o. So, the sad thing is that most of these FM providers will die either by financially perishing or getting acquired by larger infrastructures like AWS, Azure, and GCP. Future I am really excited about this and have some thoughts on this. I will get back to you guys on this if you found this post to be interesting. In the mean time, feel free to ask me questions and let's discuss about... anything! Cheers.","When I'm analyzing a company, I don't WANT ""user experience"". I want data points while hoping to high heavens that the auditors aren't corrupt, that the CEO isn't a lying psychopath and that the accountants aren't screwing with the statements.Currently the LLMs cant audit anything, will absolutely lie when they don't have access to facts, and can and will screw with statements.I wouldn't trust an LLM for any sort of financial analysis because it has to be double checked every time.",2,nan,nan,nan
,"Hi, I am a founder who is trying to build ""Google for Financial Research"" start out from equity research. Today, I'd like to share my thoughts on how the past few years has been for AI, the current status, and finally the future. I do not know everything but wish to learn new things. So, I would love to get honest thoughts on my view --- and also my product if you're interested :) Value Chain First, you can view the LM value chain similar to the computer value chain. Foundation model providers like OpenAI and Anthropic are similar to semiconductor designers(fabless; e.g., Nvidia, Qualcomm). They design the models. Performance is everything. Cloud companies like Azure, AWS, and GCP are like semiconductor manufacturers(e.g., TSMC, Samsung Electronics). They provide training resources for actually making production-grade models. Cost and reliability is everything. Finally, newly born application companies or existing ones those who are harnessing this technology is like computer companies(e.g., Apple, Dell). They don't need to know what's under the hood, as it's abstracted. User experience is everything. Past Yeah so, over the past few years. GPT. Boom! That's how it the world started to become interesting (and inflating). GPT-2 was sensational to tech guys. GPT-3 comes out, that becomes history. GPT-3.5? GPT-4. ... You get the point. OpenAI has been leading this industry ever since its emergence into the mass market. Although many competitors like Anthropic and Google has joined the league, and they also perform very well, it is OpenAI that is dominating its presence in the arena. I think Altman's plan is to make OpenAI's models to be the go-to-model for intelligent systems, and he is succeeding very well. Fyi, I am really not a big fan of Sam so don't judge me wrong. Present Now, the present. As you all know, the only real winner in this market is right now Nvidia and PaaS companies. No doubt on this. All the companies building foundation models like GPT, Claude, or Mistral is falling apart. Either suffering from wrong operation(e.g., Stability) or poor financial health. The global surge of these new companies trying to construct a new tech infrastructure has only lead to those who provide 1) datasets, 2) GPU server instances, 3) actual GPUs, 4) and energy. But in order for this waterfall to sustain, the foundation model providers need to actually generate profit to keep the cycle going. Unfortunately, infrastructures make money from people(or companies) trying to build applications. Well, applications ... Hmm ... As a founder who is actually building one, the truth is, the only two product that I've seen engineers applying to their systems is OpenAI's gpt-4o and Anthropic's Claude-3.5 Sonnet. Of course, there are open-source models that you can host by yourself, but that's just not essential for those who are trying to build AI applications. Even large software companies like Microsoft and Notion solely depend on gpt-4o. So, the sad thing is that most of these FM providers will die either by financially perishing or getting acquired by larger infrastructures like AWS, Azure, and GCP. Future I am really excited about this and have some thoughts on this. I will get back to you guys on this if you found this post to be interesting. In the mean time, feel free to ask me questions and let's discuss about... anything! Cheers.","I totally get your point. Of course, data points are really important. But great user experience in this case could be interpreted as great research experience, and great research experience originates some sanitary data with rich coverage from basic financials to notes.Also, LLMs can't audit every single statement in the world if there isn't a profound data source that it can have access to. But I think this goes same for humans. It's just that people have is authority and credibility which most machines will never obtain.So to summarize, yes data points are super important and they need be clean af. And LLMs aren't the silver bullet to everything. This goes same for Google Search too. The person who's operating the system needs to be critical and aware of misleading information. So you shouldn't just ""trust"" the outcome.(edit: added one more sentence)",3,nan,nan,nan
,"Hi, I am a founder who is trying to build ""Google for Financial Research"" start out from equity research. Today, I'd like to share my thoughts on how the past few years has been for AI, the current status, and finally the future. I do not know everything but wish to learn new things. So, I would love to get honest thoughts on my view --- and also my product if you're interested :) Value Chain First, you can view the LM value chain similar to the computer value chain. Foundation model providers like OpenAI and Anthropic are similar to semiconductor designers(fabless; e.g., Nvidia, Qualcomm). They design the models. Performance is everything. Cloud companies like Azure, AWS, and GCP are like semiconductor manufacturers(e.g., TSMC, Samsung Electronics). They provide training resources for actually making production-grade models. Cost and reliability is everything. Finally, newly born application companies or existing ones those who are harnessing this technology is like computer companies(e.g., Apple, Dell). They don't need to know what's under the hood, as it's abstracted. User experience is everything. Past Yeah so, over the past few years. GPT. Boom! That's how it the world started to become interesting (and inflating). GPT-2 was sensational to tech guys. GPT-3 comes out, that becomes history. GPT-3.5? GPT-4. ... You get the point. OpenAI has been leading this industry ever since its emergence into the mass market. Although many competitors like Anthropic and Google has joined the league, and they also perform very well, it is OpenAI that is dominating its presence in the arena. I think Altman's plan is to make OpenAI's models to be the go-to-model for intelligent systems, and he is succeeding very well. Fyi, I am really not a big fan of Sam so don't judge me wrong. Present Now, the present. As you all know, the only real winner in this market is right now Nvidia and PaaS companies. No doubt on this. All the companies building foundation models like GPT, Claude, or Mistral is falling apart. Either suffering from wrong operation(e.g., Stability) or poor financial health. The global surge of these new companies trying to construct a new tech infrastructure has only lead to those who provide 1) datasets, 2) GPU server instances, 3) actual GPUs, 4) and energy. But in order for this waterfall to sustain, the foundation model providers need to actually generate profit to keep the cycle going. Unfortunately, infrastructures make money from people(or companies) trying to build applications. Well, applications ... Hmm ... As a founder who is actually building one, the truth is, the only two product that I've seen engineers applying to their systems is OpenAI's gpt-4o and Anthropic's Claude-3.5 Sonnet. Of course, there are open-source models that you can host by yourself, but that's just not essential for those who are trying to build AI applications. Even large software companies like Microsoft and Notion solely depend on gpt-4o. So, the sad thing is that most of these FM providers will die either by financially perishing or getting acquired by larger infrastructures like AWS, Azure, and GCP. Future I am really excited about this and have some thoughts on this. I will get back to you guys on this if you found this post to be interesting. In the mean time, feel free to ask me questions and let's discuss about... anything! Cheers.","If I understand correctly, are you referring to action models to ones like Adept and Open Interpreter have been building?",0,nan,nan,nan
,"Hi, I am a founder who is trying to build ""Google for Financial Research"" start out from equity research. Today, I'd like to share my thoughts on how the past few years has been for AI, the current status, and finally the future. I do not know everything but wish to learn new things. So, I would love to get honest thoughts on my view --- and also my product if you're interested :) Value Chain First, you can view the LM value chain similar to the computer value chain. Foundation model providers like OpenAI and Anthropic are similar to semiconductor designers(fabless; e.g., Nvidia, Qualcomm). They design the models. Performance is everything. Cloud companies like Azure, AWS, and GCP are like semiconductor manufacturers(e.g., TSMC, Samsung Electronics). They provide training resources for actually making production-grade models. Cost and reliability is everything. Finally, newly born application companies or existing ones those who are harnessing this technology is like computer companies(e.g., Apple, Dell). They don't need to know what's under the hood, as it's abstracted. User experience is everything. Past Yeah so, over the past few years. GPT. Boom! That's how it the world started to become interesting (and inflating). GPT-2 was sensational to tech guys. GPT-3 comes out, that becomes history. GPT-3.5? GPT-4. ... You get the point. OpenAI has been leading this industry ever since its emergence into the mass market. Although many competitors like Anthropic and Google has joined the league, and they also perform very well, it is OpenAI that is dominating its presence in the arena. I think Altman's plan is to make OpenAI's models to be the go-to-model for intelligent systems, and he is succeeding very well. Fyi, I am really not a big fan of Sam so don't judge me wrong. Present Now, the present. As you all know, the only real winner in this market is right now Nvidia and PaaS companies. No doubt on this. All the companies building foundation models like GPT, Claude, or Mistral is falling apart. Either suffering from wrong operation(e.g., Stability) or poor financial health. The global surge of these new companies trying to construct a new tech infrastructure has only lead to those who provide 1) datasets, 2) GPU server instances, 3) actual GPUs, 4) and energy. But in order for this waterfall to sustain, the foundation model providers need to actually generate profit to keep the cycle going. Unfortunately, infrastructures make money from people(or companies) trying to build applications. Well, applications ... Hmm ... As a founder who is actually building one, the truth is, the only two product that I've seen engineers applying to their systems is OpenAI's gpt-4o and Anthropic's Claude-3.5 Sonnet. Of course, there are open-source models that you can host by yourself, but that's just not essential for those who are trying to build AI applications. Even large software companies like Microsoft and Notion solely depend on gpt-4o. So, the sad thing is that most of these FM providers will die either by financially perishing or getting acquired by larger infrastructures like AWS, Azure, and GCP. Future I am really excited about this and have some thoughts on this. I will get back to you guys on this if you found this post to be interesting. In the mean time, feel free to ask me questions and let's discuss about... anything! Cheers.","If I understand correctly, are you referring to action models to ones like Adept and Open Interpreter have been building?",1,nan,nan,nan

date of comment,main comment,comment,depth,PTR Sentiment (Comment),Flair Outlook,Flair Score
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","I’d buy nvidia any day over Intel, even with current valuations.",0,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",,1,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","I’m always taking the company with the most superior gpu. With Moore’s law and technology doubling its capacity every 18 months, gpus will have to be more and more powerful especially with things like the meta verse so I believe in the most innovative and powerful chips to be the most sought after hence nvidia continuing its upward climb, intel is old and stagnant until they prove me otherwise they have good cpus but the gpu is just way behind nvidia and amd imo",2,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",Hasn’t Moore’s Law already failed?,3,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","Pretty much, they had 3d transistors, now it seems they just cram in larger and larger dies and change their naming schemes.",4,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","I think your describing Intel, no?You don’t think the M1 would be Moore’s standard bearer?",5,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","Moore’s law was a self-fulfilling prophecy that has already banged against the very real limits of physics. There has been no more performance to be extracted down that path for years. Generic processors cannot improve any further without a complete technological change, that’s why full-custom SOICs are jumping ahead.",3,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",Sounds like you want to invest in INTC. You don't need my permission.,0,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",Maybe he wants to dump it (on us)?,1,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",Nvidia,0,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",Stop. Pumping. Garbage. Intel.,0,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",It just won't stop I swear.,1,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",Here is a perspective…NVDA is transforming from a silicon company to an applications company in front of our eyes.While Intel is getting ready to release new GPUs… NVDA is looking to sell AI as a service.,0,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","I mean Intel has Mobileye as well, which just picked up Toyota, the largest car producer. Whats the most notable software you think Nvidia has which most fuels this optimism?",1,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",Base Command.Btw I have no positions in Nvidia and have been publicly wrong about them all year long.,2,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","Base Command.I'll check it out, thanks!",3,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",They bought Mobileye back in 2017 and have done literal fuck all with the company. They only bought it in order to seem relevant in terms of autonomous driving hype.,2,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",Buying Nvidia puts for the q earnings after eth mining is done for sure. Intel is poorly run. Year or so they may be on track but not anytime soon.,0,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",eth mining never ending end date now after 2nd half of 2022. And several other coins out there which will continue to support POW.,1,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",NVDA puts? Might as well throw cash in the fireplace for better returns.At least you'd keep your house warm this winter.,1,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","Idk once the difficulty for eth mining reaches a boiling point, which it will, the market is going to flood with pretty much everything over 8gb. I’m sure there will be other coins to mine but in reality land most of those gpu’s were bought by newbies that never made their money back from $3500 3090’s and won’t. Difficulty on others will skyrocket too. Besides, it’s easier and easier to just buy crypto now anyways. Point is, millions of gpu’s on the market has happened before to nvidia and it didn’t go well. I predict it will be even worse this round since qty of miners went thru the roof. Also, puts on nvidia would have printed this week so yea.",2,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","You know this isnt the first time Intel has tried to get in the GPU business right, if it was just an issue of capital to catch Nvidia(or AMD) wouldn't they already have done it? NVIDIA GPUs are the best supported in terms of machine learning libraries and integration with common frameworks, such as PyTorch or TensorFlow. The NVIDIA CUDA toolkit includes GPU-accelerated libraries, a C and C++ compiler and runtime, and optimization and debugging tools. ASICS serve their purpose and can be made more flexible with FPGAs but they are still not as easy to deploy in mass, maybe in some specialized setups where you know exactly you want, have the resources to program it and dont expect to change much(like your government example and Telsa's switch from Nvidia to their own ASIC design). Google also has their own TPU design also, but this is not a mass product that will impact the bottom line of Intel unless they can somehow make it as flexible as Nvidia's product(which you just cant do with ASICs). Lots of companies design ASICs, they arent very profitable outside of crypto currency mining.Dont get me wrong i like INTC, NVDA, and AMD(and own stock in all)....but right now INTC is years behind AAPL, NVDA and AMD in chip design and have yet to see any viable plans to rectify this. Their factories will be key for American leadership in semiconductors when China eventually attempts to take Taiwan so they will succeed thanks to government support until they catch up in design.",0,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",". ASICS serve their purpose and can be made more flexible with FPGAs but they are still not as easy to deploy in mass, maybe in some specialized setups where you know exactly you wantDoesnt this just sound like any mature technology provided on a mass scale? Tesla self driving for instance?",1,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","no it isnt....ASICs can do one thing only. Tesla is using specialized ASICS(they designed) made at TSMC to train their neural net from top to bottom, they designed their whole system around it, few companies have the resources do to this and why many turn to Nvidia's flexible out of the box system(including Tesla until they needed much higher compute). Making ASICs is easy compared to CPUs/GPUs but its the complete software system design around them that is hard, as they have to be made together. its a niche low volume product and insignificant to intel other than maybe additional foundry product they can produce. But TSMC and Samsung are already pushing 3nm there so at 10nm Intel is years behind there also.",2,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","I mean its not like its really 3nm though now is it.You seem to be agreeing that only small companies use GPU solutions, and that once decent money is involved they would switch as they had the resources. Is that not a pretty large cap on scalability of earnings?The rub that as soon as the market grows large enough you're no longer useful. I just dont understand the hype.",3,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","3nm is still being developed but not at intel as they couldnt break 10nm.Lots of large companies use Nvidia's GPU AI solutions....Tesla could of continued using them but when you need more of one type of compute its hard to beat the value of ASICs...the thing is anyone scaling ASICs in mass have to do their own software design so yeah this is typically larger companies....but anyone can make the ASICs chips used around that with the only benefit coming from smaller nodes(ie less power used) which Intel currently cant produce.end of the day ASICs production is not something intel will be able to compete on in node tech and really wouldnt want to, as the volume is just not there...typically one and done orders, like that government job",4,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","I mean 3nm is marketing though, none of it means anything anymore.I dont see why Intel couldnt develop and produce OEM's ASICS for them, spearheaded by Mobileye and other technology they buy. Seems more scalable than Nvidia GPU's.",5,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",lol it is not marketing....who ever makes the smallest node technology gets to make the highest profit silicon. TSMC makes most of the worlds ASICS for this reason. Intel messed up by giving up on immersion photo tech from ASML and now they are paying for it.,6,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",,7,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",,8,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",,9,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","Companies with full-custom SOC ICs are the wave of the future, only those that develop their own silicon will dominate the market.IC-only companies will soon be relegated to second-class status and only those with niche-applications will have any viability in that second-tier market.AI-specific servers is the next viable market niche and NVIDIA is better matched than Intel to that market.",0,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",Intel let the ball drop against their competition just like BlackBerry and LG let the ball drop against AAPL.,0,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics",Holding 66 NVDA and have no plans of selling. Holding 0 INTC and have no plans of buying.,0,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","What you just wrote, makes no sense to be honest.",0,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","I'm no tech geniusThis sums of the rest of your post.They hired a big guns GPU architect Raja Korduri who likes to dream up shit, but with Intel's engineering talent could not produce any kind of discrete GPU that is competitive in the market. Power/perf can not match what is out there.",0,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","Sure I think a lot of it is software optimizations for games, AMD has a lot better value for money but lacks this optimization. Though you might admit this is also one of the best times to enter the ring given the shortage, perhaps they can optimize before theres a dip. Then their future fabs can hopefully increase margins.",1,nan,nan,nan
,"I'm no tech genius, but I'm looking at Intel, who has a GPU coming out in a couple months. They've got high revenues, subsidies, industry connections, a ton of new Fab, a ton of 3nm TSMC capacity, and enough capital to catch up to Nvidia. But the real reason Intel will trump Nvidia is ASICS will be more useful for machine learning. GPU are great early on, but theres never a case where power usage is irrelevant outside of development. Bitcoin is a good example of this, nobody is buying up GPU to mine bitcoins; so assuming theres some huge future market for this is crazy. So the real question is who can build machine learning and ASICS in the US, and offer it as an all in one solution to OEM who can produce the end product? https://www.tomshardware.com/news/intel-darpa-structured-asics","I'm gonna say this once. I have done business with both. One is definitely a better bet, the other is a dinosaur that will take decades of lost business to innovate.",0,nan,nan,nan

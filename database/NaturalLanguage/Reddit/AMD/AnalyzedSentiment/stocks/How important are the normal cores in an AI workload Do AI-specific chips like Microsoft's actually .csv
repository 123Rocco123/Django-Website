date of comment,main comment,comment,depth,PTR Sentiment,Flair Sentiment,Flair Outlook
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","Google has 5 generations of TPUs. Half of Google runs on TPUs. Bard and GSE with 200+ million monthly users runs on TPUv5eIs Nvidia being put out of business by Google? Amazon has its own AI accelerator. Is it stealing business?No. Because Nvidia is more than a CUDA core.In 5-10 years however, I expect the mega cloud companies to put as much of their own hardware in as possible to prevent being monopolized by a single company. They also will fund AMD as an alternative. Nvidia isn’t a true monopoly.",0,0.574,0.972,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","While Google are the clear leaders with TPUs AWS has Trainium and Inferentia, Azure has Athena.ASICs will be the way forward as training runs and inference loads scale up the cost to design and tape out a chip will easily be justified by the huge savings in overall compute costs.It's quite possible in the future we get ASICs specialized for a particular model's training run / inference workload - think the GPT6 / Gemini 2 / cloooong chip that has a hardware made to support that particular memory profile.Nvidia will still have a huge role in more general purpose tasks, but I doubt the hyperscalers and frontier labs will be reliant on them in 3 years.",1,0.517,0.935,POSITIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.",5-10 years in the future means post singularity and these companies won’t be recognizable from what they are now.,1,0.531,0.999,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.",Can you elaborate on why Google doesn't try to compete with Nvidia when tpuv5s are faster and more cost effective than a100s? Why wouldn't google try to compete in the ML chip space when they have such a good product line?,1,0.533,0.965,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","Google make hardware to be independent from Nvidia, why would others buy Google's instead of making their own instead? The hyperscalers have resource to design their own chips, while small player buy Nvidia because CUDA is tried and true, while Google's is internal project so external support is limited/not worth while to bet on.",2,0.539,0.998,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","They do, but they sell compute not hardware. You don't buy a TPU you rent a TPU cluster.They are already a hyperscaler running data centres so no need for another middleman taking part of the profits.https://cloud.google.com/tpu/pricing/?gad_source=1&gclid=CjwKCAiAjfyqBhAsEiwA-UdzJJ4_ylj9gAv_tLtngmvZGg1oYlXZ_FBAXuwoh8T6dLxJzFgtuwUkiRoC2owQAvD_BwE&gclsrc=aw.ds",2,0.512,0.993,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","They have an internal cloud hosting platform that they use for their own apps. Instead of finding a way to provide their own internal cloud hosting capabilities to external customers, they decided to take years to build out their own external Google Cloud. Forgoing the massive market share they could have garnered by having superior cloud offering available much earlier. Why would they do this, aside from managerial/organizational incompetence? Hard to say",2,0.528,0.94,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","It will take a pretty long time to happen, IMO. But I do think over time the chips will move more and more to the Googles of the world.I am old. Really old. So it is pretty interesting to watch. We started with the chips coming from the companies that made the machines. The DECs, IBMs, HPs, etc.Then we moved to third party. But now we are moving back to the old way.Apple is already there for their phones and now laptops. Google is also there for their phones. But also for their cloud with the TPUs.Microsoft is late and not sure what took so long to get it. But now they are doing the same.I do not see it changing. But NVDA will be fine for a good length of time and I would not worry about it too much today.",0,0.533,0.911,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","You mentioned IBM, but I think it is safe to say that IBM still sells their powerpc based systems and even new supercomputers with power architecture are coming up.",1,0.539,0.907,POSITIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","The first thing to note here is that the compute cost of inference is dropping all the time. Once trained models can be made to run more efficiently. For example, I can run LLaMA 2 locally on my Macbook and it runs great. The world doesn't necessarily need GPUs in a world where the best AI models can run on consumer hardware.Really the only place where NVDA is needed right now is in data centers for training and I'd guess the main long-term priority there will be cost. Even if NVDA has the best GPUs it doesn't necessarily mean you're going to get the best bang for your buck with NVDA. If other competitors have something decent enough so long as they're priced attractively they'll begin to take market share from NVDA.I think if you're bullish NVDA you basically have to assume that NVDA's CUDA software is so much better and so well liked by developers that companies will be willing to pay a premium just to use it. And I think that will happen to some degree, but again you'd think there will be a point at which the cost to retrain devs to use some other software is going to look attractive...For me it just keeps coming back to the fact that it's very hard to maintain pricing power when the long-term moat appears to mostly be cost.For now NVDA is basically the only game in town and every company wants to get into the AI hype so they're going to buy NVDA GPUs whatever the price, but I think slowly you'll see competitors and developers start looking to cheaper alternatives. And as that adoption of alternatives increase that's probably when the market will reprice the long-term growth and margin story. Maybe that's not for a few years yet, but I'd be amazed if it isn't coming.",0,0.538,0.997,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","I am going to point this out again, If AI becomes actual gold, every company will make their own chip/AI. Most likely AI will be the next thing, who would ever want their progress hamstrung by another company if the race to make the best ensured domination of that space?",0,0.598,0.829,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","I'm thinking more along the lines of, where will all the companies that actually can't allocate the capex needed to have their own chips go? Microsoft/Amazon/Google/etc will obviously have their own architectures, but if they're all making vendor-locked architectures it means some cross-party middleware/software stack will gain importance as these companies not creating their own chips will be signing deals with the hardware providers to integrate their solutions.Then it just becomes a question of performance, space and power efficiency. Even space to some extent is irrelevant to these companies because they don't care about the physical layout of the datacentre as much as they care about 99.9999999% uptime reliability. Then it just becomes a matter of performance:cost.Google and Nvidia are both capable hardware-wise of being the dominant architectures but obviously the software stack is currently heavily in Nvidia's favour in terms of public availability and ecosystem.",1,0.529,1.0,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","They will still buy from Nividia, but they are small gains, or at Nividia's growth targets, worthless gains. They will still make money, but no where near the current demand.Nividia is gold right now, because they are selling the shovels to mine the gold to everyone. If the people mining the gold start making their own shovels, then they are fucked. All the companies that do not have the capex will still buy, but they are less than 5%-10%. Most of Nividia's gains are coming from the whales. The dolphins and normal companies will still buy, but man if Apple/Google/Amazon ect.... make their own, a lot of their growth market disappears. China/India are also going to try and do their own thing.Again who knows though honestly.",2,0.538,1.0,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","I'm a huge nvda bull, but I recognize this as a genuine risk.I take comfort that even their direct lifetime rival AMD has not been able to do what the hyperscalers are attempting. Not to mention nvda has been compounding using their own AI tech to help design the chips.It would be untenable for the hyperscalers to not be making their own chips - but I imagine their own chips will be mostly leveraged for their own worklows (like copilot on azure, and all the other AI enterprise offerings they will have), while the cutting edge research could still be limited to more generically powerful chips like NVDA.I need to learn more, but I would say there is a reason NVDA was positioned to both deliver and capitalize on the AI moment, and that while everyone can now see this is valuable and the way of the future, I do not think it will be so easy for anyone to replicate on short order. And you have to compete against the rate of improvement, not against whatever performance the chips have now.But I agree - no one truly knows. It is an evolving situation that deserves close attention.",3,0.531,0.983,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.",They’ll all be hamstrung by tsm tho,1,0.501,0.999,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.",doesnt china have 7nm technology ?,2,0.579,0.999,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","If AI becomes actual gold, every company will make their own chip/AI.How long will it take to catch up? Since it's a field where you always want the very best to be competitive.",1,0.595,0.515,POSITIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","That depends on what the AI needs to do. If it is do everything, like a jack of all trades literally, it will take a long time. If it is specific (which we are already seeing with modules, not very long). AGI or do everything will be quite a ways off and unusable at at consumer scale (not understanding how to use it to get what they want), but AI that is focused on lets say Investment, Military, Urban planning ect... much more focused and much easier to focus use as a Human.Another way to look at it, look at what people are spamming forms with, the most basic stuff, repeated endlessly and each thinks they are unique. Very few outliers that have done more than the bare bones in challenging the AI and what would come out of the AI. I think a general every day use AI is not going to take long to come to market as a Siri/personal AI, specialized AI will be behind gov/companies door and indie open sourced will be fast as well. But all in one, very long, but we don't need that for a long time.A lot of AI is currently built off just a few players, with everyone else finding niche's or pieces of that pie and selling it as a business charging for the API.",2,0.543,0.993,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","Exactly this. If you’re a service offering and you charge $1, NVDA takes $.80. No company will allow the hardware part of the supply chain to eat up that much margin. They’d rather not put out a service until prices come down.",1,0.568,0.974,POSITIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","Nvidia is going to keep dominating the market for training chips. But inference is considered to be a more important growth market, and there is a lot more competition there.",0,0.572,0.991,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","Can you help me understand why Google or Microsoft cannot win the training market?Inference as I understand it is simply applying input not provided in the training data to receive an output which is (hopefully) correct, so that becomes the application side of things.However, aren't the companies actually creating trained networks more likely to make bucket-loads of cash because application-side businesses will be wanting to buy those networks and a lot of it may not be provided exclusively to any one business?",1,0.533,0.997,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","I think if the underlying computational structure of the field doesn’t change at all ASICs are pretty strongBut AI is rapidly changing, little is known about even the model underlying the chatbots, its only a few years old. NVDA pushed out an update to its chips that doubled their speed a month ago by changing the way they process AI loads.What if a completely different computational model is better? Do the ASICs become worthless?So, as long as things keep changing more general processors are king.Also as a practical matter, the amount of compute necessary to run all of GOOG search traffic through chat bots is orders of magnitude greater than what they have now, which is why they haven’t pushed it out broadly and why MSFT could (because Bing has orders of magnitude lower market share)So the amount of compute available over the next few years is going to have to grow by orders of magnitude, which if NVDA gets a small piece even is huge.",0,0.526,1.0,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.",I would be scared as hell of Next Silicon if I was any of these large GPU/accelerator companies.,0,0.539,0.526,POSITIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.",In a few years each big player will have data centers built with their custom hardware... Intel and tsmc will be the foundaries... Paper designers like nvda and amd will slowly decline,0,0.548,0.961,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","More likely Samsung and TSMC, but who knows - IFS uptake hasn't been that rapid so far.",1,0.5,0.989,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","CUDA is more than hardware, it is also back end software API on which algorithms are builtIn house Goog Amazon or MSFT chips mean inhouse I e. No body else uses them outside this company for research development or product etcThis means that nobody outside these companies learn to use themThis means that smaller companies go for technology that is relatively open source for which the hardware is Nvidia unfortunatelyIf Goog Amazon Microsoft etc want to sell their hardware, they need to embrace open source use of their backend software API e.g introducing in tensor flow the backend API for their software, supporting different devices etcSee examples: Intel mkl Open CL CUDA etcIn summary, you have to provide the software drivers available outside your company in open source for your hardware development to make sense",0,0.546,0.525,POSITIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","While the CUDA ecosystem is strong, that is more because of what is built on top of CUDA.The knowledge pool behind those applications can definitely transition to some other platform especially if it is supported on multiple hardware architectures if it reduces their dependence on Nvidia and the economics makes sense.So there might be a gradual competing snowball but Nvidia could remain a juggernaut.",1,0.523,0.505,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.",Total BS. Google (TPU) and AWS (Inferentia) AI hardware is available for public use.https://cloud.google.com/tpuhttps://aws.amazon.com/machine-learning/inferentia/,1,0.526,0.784,POSITIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","How many computers have you bought in the last 2 years that contain a TPU? Or inferentia or whatever it is you call itLike I said, if you make a highly specialized equipment tailored to your organization, don't be surprised if others don't adopt it as a standardOpen source and Open API is the key",2,0.548,0.6,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.",These organisations rent the resources on AWS or some other platform. AI developers dont want the added headache of full stack datacentre management unless they already have existing datacentre businesses.,3,0.525,0.956,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","If i am building a huge model, i 'd be willing to spend a few weeks to change my libraries to use a non-cuda API , since the training of the model will take months anyway and will be the bulk of the cost. it s inevitable that cuda competitors will catch up. and surely we will end up with an open source standard for them",1,0.52,1.0,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.",There already is open source it’s called RISC-V,2,0.514,0.768,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","we should expect tensor cores to become dirt cheap in the next 2 years. someone will make an open source design to offload 90% of inference computation (training only needs to happen once), and ultimately the edge will be dictated by cheap electricity, like they did with crypto.where is cheap electricity? iceland/russia/china?And then we may have have completely new technologies like physical deep networks that use physics principles to run deep networks. This may completely upend the fieldhttps://www.nature.com/articles/s41586-021-04223-6",0,0.526,1.0,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.","Is the L40s geared more towards the inference projects than towards training?You say open source design for inference offload, but actually constructing the silicon requires a lot more work and with more packing efficiency being demanded every year, and Moore's law's limits being tested at the atomic level year after year, I wonder how many companies will be willing to simply copy and paste some open source design into their silicon and then simply tweak it.",1,0.554,0.993,NEGATIVE
,"Nvidia chips contain a huge number of CUDA cores and a separate set of Tensor cores to accelerate instructions relevant to AI workloads. While I don't expect Nvidia's dominance to change in the next 3-4 years, some of their large customers are researching their own chips. Microsoft and Amazon are known to be working on it, Google is already known to have their own silicon, as is Apple. What I would like to understand is how would Nvidia's offerings fit into their business model if the cost/performance/space efficiency of those in-house custom chips is better than what Nvidia's current and future models can offer? I don't think Nvidia's Mellanox business is threatened, because even systems containing those chips will need to be networked to each other, but their current growth comes largely from the sale of datacentre GPUs. Note: I do own ARM, Nvidia, TSMC, Google, Apple and AMD stocks, which are all relevant to this discussion. I don't currently own Microsoft or Amazon stocks. I also own several other stocks but I'm not sure if they are relevant here.",but you wouldnt need the highest-end chip fabrication for these machines. they are not power-constrained like mobile phones and laptops. china will probably make tons of them with whatever lithography machines are available,2,0.526,0.941,NEGATIVE

date of comment,main comment,comment,depth,PTR Sentiment,Flair Sentiment,Flair Outlook
,,GPT-REEEE,0,0.5,0.999,NEGATIVE
,,"Jim Keller is one of the most influential and innovative figures in Semiconductors. This is like calling Einstein a generic German academic.When Jim Keller speaks on Semi’s, the semi community listens.",0,0.508,0.996,POSITIVE
,,Former engineer. lol. Its Jim KellerHeadline makes it seem like some random peon.,0,0.505,0.996,NEGATIVE
,,"""former engineer"" - the most respected engineer/chip architect in the business.",1,0.556,0.998,POSITIVE
,,"The article is written all around this phrase:He thinks Nvidia is becoming like IBM back in the day but in the AI world.Jim Keller is legit and we should listen, but the article isn't Jim Keller. It's just that sentence.",0,0.531,1.0,NEGATIVE
,,Problem that he worked at Tesla so maybe he is already burnout,0,0.504,1.0,NEGATIVE
,,Jim Keller is not just some random former engineer. He literally revived AMD,0,0.562,0.997,POSITIVE
,,Nvidia is very good company but it is extremely overvalued. ASICs are future of AI not GPUs.,0,0.644,0.997,NEGATIVE
,,Well what nvidia is building is asic I think a lot of ppl have misconception about this since nvidia keep naming it as gpu. H100 is literally ml accelerator.,1,0.534,0.93,NEGATIVE
,,Correct but even amd had better flop than nvidias chip and thats not the reason why ppl buy nvidias chip. It is hw/sw stack,2,0.555,0.99,NEGATIVE
,,Correct but even amd had better flop than nvidias chip and thats not the reason why ppl buy nvidias chip. It is hw/sw stack,3,0.555,0.99,NEGATIVE
,,The shoe company?,1,0.87,0.98,NEGATIVE
,,It’s how they plan to run laps around competitors,2,0.513,0.819,NEGATIVE
,,It would be strange if there wasn't a lot of overlap in the skills to make those,1,0.507,0.945,NEGATIVE
,,"Who cares? The question isn't ""how overvalued is it?"", the question is ""how overvalued can it get?""",1,0.502,1.0,NEGATIVE
,,Tensor cores are literally ASICs,1,0.499,0.998,POSITIVE
,,What sort of integrated circuit do you think would be better than a GPU for AI?,1,0.555,0.991,NEGATIVE
,,AIPU?,2,0.5,0.998,NEGATIVE
,,"So, a highly specialized chipset designed to perform extremely well for AI-related processing? Great idea. Oh wait, NVIDIA is already selling that. Woops!",3,0.542,1.0,NEGATIVE
,,"Well, yeah. GPUs are really versatile, but ASICs can be more efficient at solving strictly defined problems. An AI application framework could be developed in conjunction with development of application-specific integrated circuits (ASICs). But that would also present hardware limitations if and when programmers needed to make a change in the framework.I think NVIDIA's CUDA system represents a sort of bridge between the two ideas - something of a generalist ASIC (paradoxical as that may sound).",4,0.531,0.916,NEGATIVE
,,And what is to prevent Nvidia from making them and doing a better job if they turn out to be more profitable than their current product offerings? You think they are unaware of them? Do you think they will be taken by surprise?,5,0.532,0.997,NEGATIVE
,,"I am really not sure whose posts you are arguing against here. I think this thread has run its course, but feel free to continue posting if you like.",6,0.507,0.996,NEGATIVE
,,Yeah you probably know more than all the brilliant minds at Nvidia. They should hire you and you can run the company so you can clearly get them going into right direction since they clearly have no idea what the future of AI is going to be.,1,0.572,0.95,POSITIVE
,,ASICs are not even used for AI computing. Are you confusing Bitcoin mining with AI computing?,1,0.556,1.0,NEGATIVE
,,"ASIC is: Application Specific Integrated Circuit.Which means, that any chip that is designed to do one algorithm well can be called ASIC",2,0.53,0.567,NEGATIVE
,,Yes it’s used for specific reasons tasks like solving complicated math problem (mining) gpus are superior in AI,3,0.519,0.996,POSITIVE
,,"Nvidia has tensor cores, which is literally ASIC for matrix multiplication.",4,0.524,0.988,POSITIVE
,,This is literally not true at all. It is the GPU not an ASIC. ASIC are specifically designed for 1 task,5,0.505,1.0,NEGATIVE
,,They shouldn't be mentioned in the same sentence. IBM is quite possible the worst tech company alive.,0,0.585,1.0,NEGATIVE
,,"Now, sure. But they used to be the hottest shit ever. And after that fucking HP was thought to be the rockstars of the tech sector for a decade. Hell, Cisco was the big dog of the tech sector not too long ago. Nvidia won't stay on top forever.",1,0.535,0.998,NEGATIVE
,,"Those are the exceptions. You can’t lean on the exceptions to the rule. Businesses fade and fail all the time, even if they hit epically high highs for their sector.Of course it is possible, I’d never say it’s not. But I do highly doubt Nvidia will land among those few over time considering their products. They are a shovel company during the discovery of gold deposit. They very well might continue innovating and successfully diversify their revenue streams; but historically they are likely going to end up along the same lines as the myriad of other companies who struck gold and begin to slide with each year further and further from relevancy. Perhaps at no fault of their own, just the whim of market conditions.That said I do see them continuing to do well enough as a company over the longer term. They might not even come down, but they likely will stay relatively stagnant. I do not see them consistently stand among the wealthiest companies without massive expansion and diversification shielding themselves against inevitable competition. I’m sure related conversations are being held left and right daily in their board rooms.",2,0.548,0.989,NEGATIVE
,,"Those are the exceptions. You can’t lean on the exceptions to the rule. Businesses fade and fail all the time, even if they hit epically high highs for their sector.Of course it is possible, I’d never say it’s not. But I do highly doubt Nvidia will land among those few over time considering their products. They are a shovel company during the discovery of gold deposit. They very well might continue innovating and successfully diversify their revenue streams; but historically they are likely going to end up along the same lines as the myriad of other companies who struck gold and begin to slide with each year further and further from relevancy. Perhaps at no fault of their own, just the whim of market conditions.That said I do see them continuing to do well enough as a company over the longer term. They might not even come down, but they likely will stay relatively stagnant. I do not see them consistently stand among the wealthiest companies without massive expansion and diversification shielding themselves against inevitable competition. I’m sure related conversations are being held left and right daily in their board rooms.",3,0.548,0.989,NEGATIVE
,,Nobody is claiming they will stay on top forever. Just for the next 3-5 years. There are many trillions of dollars to he earned during that timeframe.,2,0.525,0.999,POSITIVE
,,I think the comparison is how they both dominated the industry in the beginning. IBM was the de facto standard for computing back in the day. Years of misguided leadership tanked their lead.,1,0.521,0.968,NEGATIVE
,,Fair enough.,2,0.512,0.517,NEGATIVE
,,They just havnt innovated in a while. They used to be top dogs,1,0.517,1.0,NEGATIVE
,,It’s a massive company. Some of their offerings are highly competitive. They were also major contributors to getting Kubernetes off the ground.,1,0.589,0.994,POSITIVE
,,In the past IBM did good or great things. Now they mainly just export jobs to India.,2,0.514,0.751,NEGATIVE
,,But once they were the best in class,1,0.558,0.663,POSITIVE
,,"Yes, the good ol' 80s.",2,0.52,0.997,POSITIVE
,,It will be again with quantum tech,2,0.54,0.99,POSITIVE
,,"tl;dr - Hardware does not equal design/softwareI'm sure I'm nowhere near as smart as this nerd. But even someone with a double-digit IQ knows there is a world of difference between an IBM (Hardware in the heyday) and NVDA (Design/Software)All nascent manufacturing industries start out with fat profits and a few players. This is immediately followed by numerous competitors that rush into the industry to get a piece of the pie, slowly forcing down profit margins in exchange for volume. And eventually, these industries become dominated by oligopolies. It is the nature of tangible products to become commoditized with time (aka - productivity)Cars, TVs, Chips, PCs, etc. It's almost always the same. Go ahead and look up how many US auto manufacturers have existed in the US (Spoiler = around 3,000). 30 years ago, about 20. Today, a handful. And they focus on selling as many cars as possible and sometimes dont even make a profit on the ones they do.But in this case, we are talking about computer hardware, so I'll stay on that. I do have a tendency to ramble:People had PCs in the 70s and 80s, but they were often for those in the highest income brackets, because the things were freaking expensive. It wasn't until the very early 90s for true mass adoption of the PC to begin (primarily driven by creation of the information superhighway). That's also when the number of PC makers exploded. Why did so many companies rush in to make PCs? Because a new Apple, IBM, HP, Compaq, NEC, computer with all the fixins was around $2,000 to $3,000. Thats 30 years ago pricing - That's like paying $7,000 for a new PC today. There was lots of money to be made, hence the PC gold-rush.Eventually you had upstarts that came in as the cheaper plays, Gateway, Dell, etc. Their claim to fame was getting a whole PC set-up for $1,500-$2,000. This led to the true cost-conscious builders - See: eMachines with their $499 computers. Today you can get a desktop equivalent powered laptop for $300. Something that would have been considered a ludicrous joke 20 years ago.This race to the bottom leads to inevitable outcomes: Most manufacturers go out of business - Ex: Compaq (Once the world leader and introduced the first laptop). Some become niche: See Apple. And some manufacturers dominate through their processes - Ex: Dell and its direct-to-consumer business. But even they remain beholden to volume and profit margins. And so, when the world has a mild PC slowdown, they struggle.And then some players pivot - which brings us to IBM. They sold off their laptop business to China and attempted to pivot to consulting/software. (Sidenote: Their mistake was selling their laptop business. They should have used it to sell ancillary services with higher profit margins - See: Dell). It wasn't a bad idea. They have incredible IP (Up until a year ago, they had the most patents in the world). They tried to do the AI thing before AI was truly feasible from a computational standpoint. Remember Big Blue playing chess vs Kasparov? Deep Blue, etc. In some ways, they were ahead of the game.Ultimately, they didn't pull it off and instead focused on consulting.To compare a company that produced hardware to become an industry titan (IBM started by making typewriters - hence the International Business Machine moniker) to one that produces nothing, save intellectual property, is quite silly.NVDA should be compared to MSFT or AAPL. They both rely on the production of hardware, but they themselves make none of it; the hardware is just a delivery system. MSFT doesn't give a crap who makes PCs. The only thing that matters is Windows, Office, and Azure are loaded onto it. AAPL doesn't care about which manufacturer/country produces their new iphone - whether it's in Vietnam, China, or India. Those phones are simply tools that allow you to access the apps on their appstore/ecosystem.And that is what NVDA does with GPUs. They don't manufacture anything, but their graphics cards go into every system on the planet. And those cards are simply a computational tool that allow you access to CUDA.CUDA is everything. If and when a truly viable competitor to CUDA arises, then NVDA will be in trouble. And that is when you can value it on being just another IBM.",0,0.531,0.998,NEGATIVE
,,"Holy shit. It's Chad Dickens.I am a bot, and this action was performed automatically. Please contact the moderators of this subreddit if you have any questions or concerns.",1,0.501,0.937,POSITIVE
,,"This “pivot.” Is it in the room with us now?I am a bot, and this action was performed automatically. Please contact the moderators of this subreddit if you have any questions or concerns.",1,0.508,0.991,POSITIVE
,,The problem with that comparison is a shit ton of companies are buying a shit ton of Nvidia hardware and then buying subscriptions to that hardware,0,0.529,1.0,NEGATIVE
,,Sort of like IBM mainframes?,1,0.502,0.947,NEGATIVE
,,"I don’t know, I don’t know enough as I should",2,0.527,0.778,POSITIVE
,,Salty people who missed the boat gonna stay salty. See you next earnings [̲̅$̲̅(̲̅ ͡° ͜ʖ ͡°̲̅)̲̅$̲̅],1,0.517,0.88,NEGATIVE
,,"This is going to be a tangent from the article, but I never understood the hype around Jim Keller.People make it sound like this guy is an engineer who just single-handedly designs CPU architecture, like he just went into the desert for 40 days and showed back up with the Zen architecture. Semis are just way too complex for that. People want one face they can put on some innovation, ""this guy created that!"", but chip design isn't something that one guy can do. For leading-edge CPUs, it's not a task that even 100 guys can do. At big corporations, it's thousands of engineers working across a hundred different teams.Calling Keller a brilliant architect who built all these chips is like calling Napoleon a brilliant foot soldier who single-handedly won Austerlitz. They haven't done that foot-slogger junk in decades. They direct armies now.",0,0.512,1.0,NEGATIVE
,,It’s people with vision and the capacity to understand the challenges that those 1000 individuals have when trying to enact their vision. AMD was unable to create a competitive product for years. And the first project Keller was on was the basis for their current success 9 years later.You can have smart people but if you can’t align them they might as well be chickens without their heads.,1,0.534,1.0,POSITIVE
,,But does it make bitcoin?,0,0.51,0.998,NEGATIVE
,,I plugged my Bitcoin into my Google and then transferred it to my NVIDIA via the Tesla. Still haven't received an email from Instagram so I'm watching Tiktok.,1,0.551,0.707,POSITIVE
,,this guy bitcoins,2,0.5,0.995,NEGATIVE
,,This 😂,2,0.5,0.839,POSITIVE
,,They'll probably send you a WUPHF. https://www.youtube.com/watch?v=uRoCMde-Cm8,2,0.506,1.0,NEGATIVE
,,Nvidia is just joking everything is fine!!! There are no risk of:failing on earnings like ASML todaychina takes over TaiwanTrump push US producer like Intel an punish taiwan chip firmsmonopoly penalties for nvidia like in franceeconomy slowdown dues to reduces investitions in AI (microsoft already cuts expenses)RotationStupid people selling AI stocks for the next small caps hypeoverbought stock - good news just not be hearedsome fakes news more....Pleas buy nvidia calls - i swear everything is right.,0,0.55,1.0,NEGATIVE
,,"Lol you’ve been in SNDL for years, your opinion holds negative weight.Post all time and positions or stfu",1,0.512,0.991,NEGATIVE
,,When has nvidia missed on earnings in the past year give me a break,1,0.646,0.996,NEGATIVE
,,I talk about the future. Onetime they will miss. Not earnings but future expectations like ASML today.,2,0.549,0.634,POSITIVE
,,26 billom earnings means they should be worth over 3 trillion. Holy fuck you regard.,2,0.536,0.986,NEGATIVE
,,Short them then. Be sure to post the result.,3,0.486,0.999,NEGATIVE
,,I didn't say anything about the value of the stock you mentally challenged fools. Just that nvidias value is obviously not correlated to its earnings.,4,0.559,1.0,NEGATIVE
,,"In other words you don't stand by your comments which are based on nothing and you are admitting it with this reply. Thanks for letting us know.If you believed what you are trying to convince us of, you would be shorting them right now with every penny you have. Simple as.",5,0.522,0.544,NEGATIVE
,,Then why small caps go down too?,1,0.503,0.97,NEGATIVE
,,Someone missed the rocket to the moon and is salty.,1,0.502,1.0,NEGATIVE
,,"NVidia's a legit business, but they are priced 10x too high.",1,0.588,0.999,NEGATIVE
,,44x NTM consensus earnings is 10x too high for you? You think they should trade at a 4.4x P/E? That’s certainly quite the take…,2,0.529,0.996,NEGATIVE
,,"We'll see how long those earnings last. I think they are going to lose half their business in about 2 years, when AAPL/MSFT/FB/GOOG finish a chip design cycle and take their GPUs in-house, and then NVidia will lose the pricing power to hold out for 90% margins.Heck, even if the big four don't develop their own in-house replacement, just slowing down their compute spend will smash the brakes on NVidia's revenue. People are projecting long-term stock gains out of what's been a very short-term situation.",3,0.543,1.0,NEGATIVE
,,"I agree, NVDA has a good product, but the quarters of constant earnings blowouts can't last. I predict that the other tech companies will cut back on chip spending as they see the expected earnings from AI not materialize. The when is the big question but I don't think we will see a major NVDA pullback until mid 2025-2026.",4,0.549,1.0,NEGATIVE
,,Dude is salty because he works at AMD and Tesla but not Nvidia. NVDA is up 3000% in 5 yrs whereas TSLA is up 1500% and AMD is 500%,0,0.602,1.0,NEGATIVE
,,"lmfao you clown, do you know who this guy is?JIm Keller is not salty about stock gains lol. Anywhere he wants a job, he has one... and a very senior one with huge fucking stock incentives",1,0.554,0.997,NEGATIVE
,,"nah, it's jim keller. he's a 'rockstar chip engineer.' he could be a vp or above at any semi company.",1,0.587,0.73,POSITIVE
,,"""Born 1958 or 1959""?",1,0.5,0.849,NEGATIVE
,,"""Born 1958 or 1959""?",2,0.5,0.849,NEGATIVE
,,You obviously know nothing,1,0.522,0.983,NEGATIVE
,,"Obviously, thats why I am here",2,0.5,0.995,POSITIVE
,,I don't think he needs to invest in stocks to make money anymore.,1,0.535,0.997,NEGATIVE
,,Lmao,0,0.5,0.984,NEGATIVE
,,"It's the Cisco of this era, from the early 2000s",0,0.504,0.998,POSITIVE
,,Calls are fd,0,0.51,0.997,NEGATIVE
,,How sway?,0,0.5,0.999,NEGATIVE
,,Nvidia has a leading edge in GPU hardware. AMD doesn’t even compare to energy / ecosystem.That’s like saying Microsoft is becoming the next IBM of cloud.,0,0.554,0.999,POSITIVE

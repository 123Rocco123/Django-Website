date of comment,main comment,comment,depth,PTR Sentiment,Flair Sentiment,Flair Outlook
,"Nvidia has had the wildest ride these past months and shook out a 10% knife over a month ago. Brutal. On top of all that you have rando's coming out saying they sold some profits off the top and the whole interest rate thing. Let's face it. Besides Google's break out, The Mag 7 has been sideways and hard to trade. Don't get me wrong, these companies have been up but they have also been punched in the mouth a few times. With that said, nothing is more peculiar than what Amazon has just done with the retiring of it's AWS CEO and more recently, their order cancellations of Nvidia's H200's. For me, the 2 things are very linked together. The notion that your massive cloud business has NO USE of H200's is a DAMNING statement. Not for AI, because Microsoft and Open AI are killing it right now, but specifically for Amazon AWS. How do you not have an ultra well-defined blueprint for where those H200's are going to go? The very notion that you would not have a plan to replace older accelerated compute AND OR expand your data centers is astonishing to me. The 2 companies could not be more world's apart in their AI trajectory. I listened to every word out of Satya's mouth on Microsoft's earnings call and the one key question that was asked over and over again was this, ""Why were your profits for AI cloud only 7% gains?"" The response was, ""There is too much demand."" Demand is outstripping supply. I can verify this is 100000% true. The one thing that is occuring with all planned projects out there in this space is the ability to service enmasse enough throughput per use case of AI compute. Now, a lot of that is latency which is improved with GPT upgrades such as GPT-4o. It's faster so you can put more throughput through the pipe and that is much better for everyone's use case and scalability. Moreover, Microsoft per this build event is putting AI everywhere in their product line. The AI is going to be coming out of your ears, nose and mouth. Open AI has invented HER. ScarJo lawsuits aside ""HER"" is here. It maybe version 1.0 but it's HER for sure. It is spectacular. And OpenAI keeps announcing this stuff everytime someone gets a whiff of thinking they are going to release something ""awesome"" for an AI offering. Everyone else is literally and desperately trying to catch up. On one hand, it's an ARM's race with Nvidia holding all the AI bullets. But in this war are there signs of defeat? In the very least there is some retreat. AWS may become the first casualty of the AI Wars. Reporting that they forgo an entire order of H200's makes absolutely no sense. They say they want to wait for the newer chips but that literally tells me your business model is in bad shape now and they see it in their books presently. Nobody, other than AWS cancelled their H200's. In fact, Sam Altman just was in a photo with Jensen getting their first H200. The implication here is for all other cloud providers, including sovereign nations, start to worry that they ultimately won't be able to compete on the scale and execution that Open AI and Microsoft have. The answer, to me, is that there is NO way, zero possibility, that the entire world is going to stand there and watch Microsoft and Open AI dominate the AI race. Asia's not going to back down, Europe isn't going to back down, Australia isn't going to back down under. Japan... Well, Japan is going to Open AI so. However, it is clear that AWS flinched and they're in trouble. While their cloud business may be fine right at this moment how long can them not having a frontier model start materially hurting their cloud business overall? Also, Microsoft's revenues are larger than many countries GDP. How much can the world really throw at sovereign AI in earnest when they don't even have the capacity to really compete financially if AWS can't even do it? Apple, has already capitulated and is probably going with OpenAI for their AI needs. Sora stopped a movie production studio from ever happening. Is this a consolidation of the AI power? Nvidia, must prove this quarter that this not the case. Those digital twins and DGX cloud systems need to show that there is great use. Meaning, I want to hear an analyst ask this question. What is the usage of the DGX cloud that is being provided by the major cloud companies and rest of world overall. Meaning, are people using DGX cloud offerings that are licensed and provided in the major cloud vendors. Apparently, not really for AWS. But that analysis is very important for how Nvidia data centers go. Yes, GPT/LLM's are one thing but all of other AI being done X GPT/LLM's and inference needs to be the lion share of the growth for Nvidia to keep powering forward. 2. What percentage of AI workload in Nvidia's business is NONE LLM Related. This is a critical question because it would help to understand how much is all of this hype AI shit going on, how much is LLM usage, and how much is other things accelerated compute based that is not hype and or LLM training and usage. Where is the growth coming from? Robotics, protein folding, teenagers in their basement trying to make the next big video game. Where, What, Why and How. Even with the Nvidia offering all of their rock star concert conference offerings they are not going to realize billions from that for some time. I think they beat this quarter and give ok guidance. There will be a slight sell down and it gets picked up and eaten up the following day for a fantastic call heading into Q2025. The only way this stock doesn't go down with all of these headwinds that Nvidia must answer for is if they do a stock split. If they stock split this moons 15% over the week. I have a small position and looking to add more. No Split 9%+ for the week Split 15+ for the week",Itâ€™s why Amazon bounced yesterday in the afternoon and ran to 185 this morning,0,0.511,0.997,NEGATIVE
,"Nvidia has had the wildest ride these past months and shook out a 10% knife over a month ago. Brutal. On top of all that you have rando's coming out saying they sold some profits off the top and the whole interest rate thing. Let's face it. Besides Google's break out, The Mag 7 has been sideways and hard to trade. Don't get me wrong, these companies have been up but they have also been punched in the mouth a few times. With that said, nothing is more peculiar than what Amazon has just done with the retiring of it's AWS CEO and more recently, their order cancellations of Nvidia's H200's. For me, the 2 things are very linked together. The notion that your massive cloud business has NO USE of H200's is a DAMNING statement. Not for AI, because Microsoft and Open AI are killing it right now, but specifically for Amazon AWS. How do you not have an ultra well-defined blueprint for where those H200's are going to go? The very notion that you would not have a plan to replace older accelerated compute AND OR expand your data centers is astonishing to me. The 2 companies could not be more world's apart in their AI trajectory. I listened to every word out of Satya's mouth on Microsoft's earnings call and the one key question that was asked over and over again was this, ""Why were your profits for AI cloud only 7% gains?"" The response was, ""There is too much demand."" Demand is outstripping supply. I can verify this is 100000% true. The one thing that is occuring with all planned projects out there in this space is the ability to service enmasse enough throughput per use case of AI compute. Now, a lot of that is latency which is improved with GPT upgrades such as GPT-4o. It's faster so you can put more throughput through the pipe and that is much better for everyone's use case and scalability. Moreover, Microsoft per this build event is putting AI everywhere in their product line. The AI is going to be coming out of your ears, nose and mouth. Open AI has invented HER. ScarJo lawsuits aside ""HER"" is here. It maybe version 1.0 but it's HER for sure. It is spectacular. And OpenAI keeps announcing this stuff everytime someone gets a whiff of thinking they are going to release something ""awesome"" for an AI offering. Everyone else is literally and desperately trying to catch up. On one hand, it's an ARM's race with Nvidia holding all the AI bullets. But in this war are there signs of defeat? In the very least there is some retreat. AWS may become the first casualty of the AI Wars. Reporting that they forgo an entire order of H200's makes absolutely no sense. They say they want to wait for the newer chips but that literally tells me your business model is in bad shape now and they see it in their books presently. Nobody, other than AWS cancelled their H200's. In fact, Sam Altman just was in a photo with Jensen getting their first H200. The implication here is for all other cloud providers, including sovereign nations, start to worry that they ultimately won't be able to compete on the scale and execution that Open AI and Microsoft have. The answer, to me, is that there is NO way, zero possibility, that the entire world is going to stand there and watch Microsoft and Open AI dominate the AI race. Asia's not going to back down, Europe isn't going to back down, Australia isn't going to back down under. Japan... Well, Japan is going to Open AI so. However, it is clear that AWS flinched and they're in trouble. While their cloud business may be fine right at this moment how long can them not having a frontier model start materially hurting their cloud business overall? Also, Microsoft's revenues are larger than many countries GDP. How much can the world really throw at sovereign AI in earnest when they don't even have the capacity to really compete financially if AWS can't even do it? Apple, has already capitulated and is probably going with OpenAI for their AI needs. Sora stopped a movie production studio from ever happening. Is this a consolidation of the AI power? Nvidia, must prove this quarter that this not the case. Those digital twins and DGX cloud systems need to show that there is great use. Meaning, I want to hear an analyst ask this question. What is the usage of the DGX cloud that is being provided by the major cloud companies and rest of world overall. Meaning, are people using DGX cloud offerings that are licensed and provided in the major cloud vendors. Apparently, not really for AWS. But that analysis is very important for how Nvidia data centers go. Yes, GPT/LLM's are one thing but all of other AI being done X GPT/LLM's and inference needs to be the lion share of the growth for Nvidia to keep powering forward. 2. What percentage of AI workload in Nvidia's business is NONE LLM Related. This is a critical question because it would help to understand how much is all of this hype AI shit going on, how much is LLM usage, and how much is other things accelerated compute based that is not hype and or LLM training and usage. Where is the growth coming from? Robotics, protein folding, teenagers in their basement trying to make the next big video game. Where, What, Why and How. Even with the Nvidia offering all of their rock star concert conference offerings they are not going to realize billions from that for some time. I think they beat this quarter and give ok guidance. There will be a slight sell down and it gets picked up and eaten up the following day for a fantastic call heading into Q2025. The only way this stock doesn't go down with all of these headwinds that Nvidia must answer for is if they do a stock split. If they stock split this moons 15% over the week. I have a small position and looking to add more. No Split 9%+ for the week Split 15+ for the week",Itâ€™s why Amazon bounced yesterday in the afternoon and ran to 185 this morning,1,0.511,0.997,NEGATIVE
,"Nvidia has had the wildest ride these past months and shook out a 10% knife over a month ago. Brutal. On top of all that you have rando's coming out saying they sold some profits off the top and the whole interest rate thing. Let's face it. Besides Google's break out, The Mag 7 has been sideways and hard to trade. Don't get me wrong, these companies have been up but they have also been punched in the mouth a few times. With that said, nothing is more peculiar than what Amazon has just done with the retiring of it's AWS CEO and more recently, their order cancellations of Nvidia's H200's. For me, the 2 things are very linked together. The notion that your massive cloud business has NO USE of H200's is a DAMNING statement. Not for AI, because Microsoft and Open AI are killing it right now, but specifically for Amazon AWS. How do you not have an ultra well-defined blueprint for where those H200's are going to go? The very notion that you would not have a plan to replace older accelerated compute AND OR expand your data centers is astonishing to me. The 2 companies could not be more world's apart in their AI trajectory. I listened to every word out of Satya's mouth on Microsoft's earnings call and the one key question that was asked over and over again was this, ""Why were your profits for AI cloud only 7% gains?"" The response was, ""There is too much demand."" Demand is outstripping supply. I can verify this is 100000% true. The one thing that is occuring with all planned projects out there in this space is the ability to service enmasse enough throughput per use case of AI compute. Now, a lot of that is latency which is improved with GPT upgrades such as GPT-4o. It's faster so you can put more throughput through the pipe and that is much better for everyone's use case and scalability. Moreover, Microsoft per this build event is putting AI everywhere in their product line. The AI is going to be coming out of your ears, nose and mouth. Open AI has invented HER. ScarJo lawsuits aside ""HER"" is here. It maybe version 1.0 but it's HER for sure. It is spectacular. And OpenAI keeps announcing this stuff everytime someone gets a whiff of thinking they are going to release something ""awesome"" for an AI offering. Everyone else is literally and desperately trying to catch up. On one hand, it's an ARM's race with Nvidia holding all the AI bullets. But in this war are there signs of defeat? In the very least there is some retreat. AWS may become the first casualty of the AI Wars. Reporting that they forgo an entire order of H200's makes absolutely no sense. They say they want to wait for the newer chips but that literally tells me your business model is in bad shape now and they see it in their books presently. Nobody, other than AWS cancelled their H200's. In fact, Sam Altman just was in a photo with Jensen getting their first H200. The implication here is for all other cloud providers, including sovereign nations, start to worry that they ultimately won't be able to compete on the scale and execution that Open AI and Microsoft have. The answer, to me, is that there is NO way, zero possibility, that the entire world is going to stand there and watch Microsoft and Open AI dominate the AI race. Asia's not going to back down, Europe isn't going to back down, Australia isn't going to back down under. Japan... Well, Japan is going to Open AI so. However, it is clear that AWS flinched and they're in trouble. While their cloud business may be fine right at this moment how long can them not having a frontier model start materially hurting their cloud business overall? Also, Microsoft's revenues are larger than many countries GDP. How much can the world really throw at sovereign AI in earnest when they don't even have the capacity to really compete financially if AWS can't even do it? Apple, has already capitulated and is probably going with OpenAI for their AI needs. Sora stopped a movie production studio from ever happening. Is this a consolidation of the AI power? Nvidia, must prove this quarter that this not the case. Those digital twins and DGX cloud systems need to show that there is great use. Meaning, I want to hear an analyst ask this question. What is the usage of the DGX cloud that is being provided by the major cloud companies and rest of world overall. Meaning, are people using DGX cloud offerings that are licensed and provided in the major cloud vendors. Apparently, not really for AWS. But that analysis is very important for how Nvidia data centers go. Yes, GPT/LLM's are one thing but all of other AI being done X GPT/LLM's and inference needs to be the lion share of the growth for Nvidia to keep powering forward. 2. What percentage of AI workload in Nvidia's business is NONE LLM Related. This is a critical question because it would help to understand how much is all of this hype AI shit going on, how much is LLM usage, and how much is other things accelerated compute based that is not hype and or LLM training and usage. Where is the growth coming from? Robotics, protein folding, teenagers in their basement trying to make the next big video game. Where, What, Why and How. Even with the Nvidia offering all of their rock star concert conference offerings they are not going to realize billions from that for some time. I think they beat this quarter and give ok guidance. There will be a slight sell down and it gets picked up and eaten up the following day for a fantastic call heading into Q2025. The only way this stock doesn't go down with all of these headwinds that Nvidia must answer for is if they do a stock split. If they stock split this moons 15% over the week. I have a small position and looking to add more. No Split 9%+ for the week Split 15+ for the week",Thatâ€™s what happens when you read a UK newspaper. The Sun is another quality one,1,0.519,0.96,NEGATIVE
,"Nvidia has had the wildest ride these past months and shook out a 10% knife over a month ago. Brutal. On top of all that you have rando's coming out saying they sold some profits off the top and the whole interest rate thing. Let's face it. Besides Google's break out, The Mag 7 has been sideways and hard to trade. Don't get me wrong, these companies have been up but they have also been punched in the mouth a few times. With that said, nothing is more peculiar than what Amazon has just done with the retiring of it's AWS CEO and more recently, their order cancellations of Nvidia's H200's. For me, the 2 things are very linked together. The notion that your massive cloud business has NO USE of H200's is a DAMNING statement. Not for AI, because Microsoft and Open AI are killing it right now, but specifically for Amazon AWS. How do you not have an ultra well-defined blueprint for where those H200's are going to go? The very notion that you would not have a plan to replace older accelerated compute AND OR expand your data centers is astonishing to me. The 2 companies could not be more world's apart in their AI trajectory. I listened to every word out of Satya's mouth on Microsoft's earnings call and the one key question that was asked over and over again was this, ""Why were your profits for AI cloud only 7% gains?"" The response was, ""There is too much demand."" Demand is outstripping supply. I can verify this is 100000% true. The one thing that is occuring with all planned projects out there in this space is the ability to service enmasse enough throughput per use case of AI compute. Now, a lot of that is latency which is improved with GPT upgrades such as GPT-4o. It's faster so you can put more throughput through the pipe and that is much better for everyone's use case and scalability. Moreover, Microsoft per this build event is putting AI everywhere in their product line. The AI is going to be coming out of your ears, nose and mouth. Open AI has invented HER. ScarJo lawsuits aside ""HER"" is here. It maybe version 1.0 but it's HER for sure. It is spectacular. And OpenAI keeps announcing this stuff everytime someone gets a whiff of thinking they are going to release something ""awesome"" for an AI offering. Everyone else is literally and desperately trying to catch up. On one hand, it's an ARM's race with Nvidia holding all the AI bullets. But in this war are there signs of defeat? In the very least there is some retreat. AWS may become the first casualty of the AI Wars. Reporting that they forgo an entire order of H200's makes absolutely no sense. They say they want to wait for the newer chips but that literally tells me your business model is in bad shape now and they see it in their books presently. Nobody, other than AWS cancelled their H200's. In fact, Sam Altman just was in a photo with Jensen getting their first H200. The implication here is for all other cloud providers, including sovereign nations, start to worry that they ultimately won't be able to compete on the scale and execution that Open AI and Microsoft have. The answer, to me, is that there is NO way, zero possibility, that the entire world is going to stand there and watch Microsoft and Open AI dominate the AI race. Asia's not going to back down, Europe isn't going to back down, Australia isn't going to back down under. Japan... Well, Japan is going to Open AI so. However, it is clear that AWS flinched and they're in trouble. While their cloud business may be fine right at this moment how long can them not having a frontier model start materially hurting their cloud business overall? Also, Microsoft's revenues are larger than many countries GDP. How much can the world really throw at sovereign AI in earnest when they don't even have the capacity to really compete financially if AWS can't even do it? Apple, has already capitulated and is probably going with OpenAI for their AI needs. Sora stopped a movie production studio from ever happening. Is this a consolidation of the AI power? Nvidia, must prove this quarter that this not the case. Those digital twins and DGX cloud systems need to show that there is great use. Meaning, I want to hear an analyst ask this question. What is the usage of the DGX cloud that is being provided by the major cloud companies and rest of world overall. Meaning, are people using DGX cloud offerings that are licensed and provided in the major cloud vendors. Apparently, not really for AWS. But that analysis is very important for how Nvidia data centers go. Yes, GPT/LLM's are one thing but all of other AI being done X GPT/LLM's and inference needs to be the lion share of the growth for Nvidia to keep powering forward. 2. What percentage of AI workload in Nvidia's business is NONE LLM Related. This is a critical question because it would help to understand how much is all of this hype AI shit going on, how much is LLM usage, and how much is other things accelerated compute based that is not hype and or LLM training and usage. Where is the growth coming from? Robotics, protein folding, teenagers in their basement trying to make the next big video game. Where, What, Why and How. Even with the Nvidia offering all of their rock star concert conference offerings they are not going to realize billions from that for some time. I think they beat this quarter and give ok guidance. There will be a slight sell down and it gets picked up and eaten up the following day for a fantastic call heading into Q2025. The only way this stock doesn't go down with all of these headwinds that Nvidia must answer for is if they do a stock split. If they stock split this moons 15% over the week. I have a small position and looking to add more. No Split 9%+ for the week Split 15+ for the week",25-1,0,0.5,0.99,POSITIVE
,"Nvidia has had the wildest ride these past months and shook out a 10% knife over a month ago. Brutal. On top of all that you have rando's coming out saying they sold some profits off the top and the whole interest rate thing. Let's face it. Besides Google's break out, The Mag 7 has been sideways and hard to trade. Don't get me wrong, these companies have been up but they have also been punched in the mouth a few times. With that said, nothing is more peculiar than what Amazon has just done with the retiring of it's AWS CEO and more recently, their order cancellations of Nvidia's H200's. For me, the 2 things are very linked together. The notion that your massive cloud business has NO USE of H200's is a DAMNING statement. Not for AI, because Microsoft and Open AI are killing it right now, but specifically for Amazon AWS. How do you not have an ultra well-defined blueprint for where those H200's are going to go? The very notion that you would not have a plan to replace older accelerated compute AND OR expand your data centers is astonishing to me. The 2 companies could not be more world's apart in their AI trajectory. I listened to every word out of Satya's mouth on Microsoft's earnings call and the one key question that was asked over and over again was this, ""Why were your profits for AI cloud only 7% gains?"" The response was, ""There is too much demand."" Demand is outstripping supply. I can verify this is 100000% true. The one thing that is occuring with all planned projects out there in this space is the ability to service enmasse enough throughput per use case of AI compute. Now, a lot of that is latency which is improved with GPT upgrades such as GPT-4o. It's faster so you can put more throughput through the pipe and that is much better for everyone's use case and scalability. Moreover, Microsoft per this build event is putting AI everywhere in their product line. The AI is going to be coming out of your ears, nose and mouth. Open AI has invented HER. ScarJo lawsuits aside ""HER"" is here. It maybe version 1.0 but it's HER for sure. It is spectacular. And OpenAI keeps announcing this stuff everytime someone gets a whiff of thinking they are going to release something ""awesome"" for an AI offering. Everyone else is literally and desperately trying to catch up. On one hand, it's an ARM's race with Nvidia holding all the AI bullets. But in this war are there signs of defeat? In the very least there is some retreat. AWS may become the first casualty of the AI Wars. Reporting that they forgo an entire order of H200's makes absolutely no sense. They say they want to wait for the newer chips but that literally tells me your business model is in bad shape now and they see it in their books presently. Nobody, other than AWS cancelled their H200's. In fact, Sam Altman just was in a photo with Jensen getting their first H200. The implication here is for all other cloud providers, including sovereign nations, start to worry that they ultimately won't be able to compete on the scale and execution that Open AI and Microsoft have. The answer, to me, is that there is NO way, zero possibility, that the entire world is going to stand there and watch Microsoft and Open AI dominate the AI race. Asia's not going to back down, Europe isn't going to back down, Australia isn't going to back down under. Japan... Well, Japan is going to Open AI so. However, it is clear that AWS flinched and they're in trouble. While their cloud business may be fine right at this moment how long can them not having a frontier model start materially hurting their cloud business overall? Also, Microsoft's revenues are larger than many countries GDP. How much can the world really throw at sovereign AI in earnest when they don't even have the capacity to really compete financially if AWS can't even do it? Apple, has already capitulated and is probably going with OpenAI for their AI needs. Sora stopped a movie production studio from ever happening. Is this a consolidation of the AI power? Nvidia, must prove this quarter that this not the case. Those digital twins and DGX cloud systems need to show that there is great use. Meaning, I want to hear an analyst ask this question. What is the usage of the DGX cloud that is being provided by the major cloud companies and rest of world overall. Meaning, are people using DGX cloud offerings that are licensed and provided in the major cloud vendors. Apparently, not really for AWS. But that analysis is very important for how Nvidia data centers go. Yes, GPT/LLM's are one thing but all of other AI being done X GPT/LLM's and inference needs to be the lion share of the growth for Nvidia to keep powering forward. 2. What percentage of AI workload in Nvidia's business is NONE LLM Related. This is a critical question because it would help to understand how much is all of this hype AI shit going on, how much is LLM usage, and how much is other things accelerated compute based that is not hype and or LLM training and usage. Where is the growth coming from? Robotics, protein folding, teenagers in their basement trying to make the next big video game. Where, What, Why and How. Even with the Nvidia offering all of their rock star concert conference offerings they are not going to realize billions from that for some time. I think they beat this quarter and give ok guidance. There will be a slight sell down and it gets picked up and eaten up the following day for a fantastic call heading into Q2025. The only way this stock doesn't go down with all of these headwinds that Nvidia must answer for is if they do a stock split. If they stock split this moons 15% over the week. I have a small position and looking to add more. No Split 9%+ for the week Split 15+ for the week",Nice analysis. Agreed on the upside move after ER. A stock split announcement would be icing lol,0,0.547,0.683,NEGATIVE
,"Nvidia has had the wildest ride these past months and shook out a 10% knife over a month ago. Brutal. On top of all that you have rando's coming out saying they sold some profits off the top and the whole interest rate thing. Let's face it. Besides Google's break out, The Mag 7 has been sideways and hard to trade. Don't get me wrong, these companies have been up but they have also been punched in the mouth a few times. With that said, nothing is more peculiar than what Amazon has just done with the retiring of it's AWS CEO and more recently, their order cancellations of Nvidia's H200's. For me, the 2 things are very linked together. The notion that your massive cloud business has NO USE of H200's is a DAMNING statement. Not for AI, because Microsoft and Open AI are killing it right now, but specifically for Amazon AWS. How do you not have an ultra well-defined blueprint for where those H200's are going to go? The very notion that you would not have a plan to replace older accelerated compute AND OR expand your data centers is astonishing to me. The 2 companies could not be more world's apart in their AI trajectory. I listened to every word out of Satya's mouth on Microsoft's earnings call and the one key question that was asked over and over again was this, ""Why were your profits for AI cloud only 7% gains?"" The response was, ""There is too much demand."" Demand is outstripping supply. I can verify this is 100000% true. The one thing that is occuring with all planned projects out there in this space is the ability to service enmasse enough throughput per use case of AI compute. Now, a lot of that is latency which is improved with GPT upgrades such as GPT-4o. It's faster so you can put more throughput through the pipe and that is much better for everyone's use case and scalability. Moreover, Microsoft per this build event is putting AI everywhere in their product line. The AI is going to be coming out of your ears, nose and mouth. Open AI has invented HER. ScarJo lawsuits aside ""HER"" is here. It maybe version 1.0 but it's HER for sure. It is spectacular. And OpenAI keeps announcing this stuff everytime someone gets a whiff of thinking they are going to release something ""awesome"" for an AI offering. Everyone else is literally and desperately trying to catch up. On one hand, it's an ARM's race with Nvidia holding all the AI bullets. But in this war are there signs of defeat? In the very least there is some retreat. AWS may become the first casualty of the AI Wars. Reporting that they forgo an entire order of H200's makes absolutely no sense. They say they want to wait for the newer chips but that literally tells me your business model is in bad shape now and they see it in their books presently. Nobody, other than AWS cancelled their H200's. In fact, Sam Altman just was in a photo with Jensen getting their first H200. The implication here is for all other cloud providers, including sovereign nations, start to worry that they ultimately won't be able to compete on the scale and execution that Open AI and Microsoft have. The answer, to me, is that there is NO way, zero possibility, that the entire world is going to stand there and watch Microsoft and Open AI dominate the AI race. Asia's not going to back down, Europe isn't going to back down, Australia isn't going to back down under. Japan... Well, Japan is going to Open AI so. However, it is clear that AWS flinched and they're in trouble. While their cloud business may be fine right at this moment how long can them not having a frontier model start materially hurting their cloud business overall? Also, Microsoft's revenues are larger than many countries GDP. How much can the world really throw at sovereign AI in earnest when they don't even have the capacity to really compete financially if AWS can't even do it? Apple, has already capitulated and is probably going with OpenAI for their AI needs. Sora stopped a movie production studio from ever happening. Is this a consolidation of the AI power? Nvidia, must prove this quarter that this not the case. Those digital twins and DGX cloud systems need to show that there is great use. Meaning, I want to hear an analyst ask this question. What is the usage of the DGX cloud that is being provided by the major cloud companies and rest of world overall. Meaning, are people using DGX cloud offerings that are licensed and provided in the major cloud vendors. Apparently, not really for AWS. But that analysis is very important for how Nvidia data centers go. Yes, GPT/LLM's are one thing but all of other AI being done X GPT/LLM's and inference needs to be the lion share of the growth for Nvidia to keep powering forward. 2. What percentage of AI workload in Nvidia's business is NONE LLM Related. This is a critical question because it would help to understand how much is all of this hype AI shit going on, how much is LLM usage, and how much is other things accelerated compute based that is not hype and or LLM training and usage. Where is the growth coming from? Robotics, protein folding, teenagers in their basement trying to make the next big video game. Where, What, Why and How. Even with the Nvidia offering all of their rock star concert conference offerings they are not going to realize billions from that for some time. I think they beat this quarter and give ok guidance. There will be a slight sell down and it gets picked up and eaten up the following day for a fantastic call heading into Q2025. The only way this stock doesn't go down with all of these headwinds that Nvidia must answer for is if they do a stock split. If they stock split this moons 15% over the week. I have a small position and looking to add more. No Split 9%+ for the week Split 15+ for the week","Bigger news is that AMD chips are doing better in terms of performance/cost for the most advanced models. The margins NVDA is charging incentives all sorts of strategies to get out of NVDA for everyone. Sure, newer chips are needed to train better models but most of the compute need is in inference which can be done with other chips",0,0.535,0.959,NEGATIVE
,"Nvidia has had the wildest ride these past months and shook out a 10% knife over a month ago. Brutal. On top of all that you have rando's coming out saying they sold some profits off the top and the whole interest rate thing. Let's face it. Besides Google's break out, The Mag 7 has been sideways and hard to trade. Don't get me wrong, these companies have been up but they have also been punched in the mouth a few times. With that said, nothing is more peculiar than what Amazon has just done with the retiring of it's AWS CEO and more recently, their order cancellations of Nvidia's H200's. For me, the 2 things are very linked together. The notion that your massive cloud business has NO USE of H200's is a DAMNING statement. Not for AI, because Microsoft and Open AI are killing it right now, but specifically for Amazon AWS. How do you not have an ultra well-defined blueprint for where those H200's are going to go? The very notion that you would not have a plan to replace older accelerated compute AND OR expand your data centers is astonishing to me. The 2 companies could not be more world's apart in their AI trajectory. I listened to every word out of Satya's mouth on Microsoft's earnings call and the one key question that was asked over and over again was this, ""Why were your profits for AI cloud only 7% gains?"" The response was, ""There is too much demand."" Demand is outstripping supply. I can verify this is 100000% true. The one thing that is occuring with all planned projects out there in this space is the ability to service enmasse enough throughput per use case of AI compute. Now, a lot of that is latency which is improved with GPT upgrades such as GPT-4o. It's faster so you can put more throughput through the pipe and that is much better for everyone's use case and scalability. Moreover, Microsoft per this build event is putting AI everywhere in their product line. The AI is going to be coming out of your ears, nose and mouth. Open AI has invented HER. ScarJo lawsuits aside ""HER"" is here. It maybe version 1.0 but it's HER for sure. It is spectacular. And OpenAI keeps announcing this stuff everytime someone gets a whiff of thinking they are going to release something ""awesome"" for an AI offering. Everyone else is literally and desperately trying to catch up. On one hand, it's an ARM's race with Nvidia holding all the AI bullets. But in this war are there signs of defeat? In the very least there is some retreat. AWS may become the first casualty of the AI Wars. Reporting that they forgo an entire order of H200's makes absolutely no sense. They say they want to wait for the newer chips but that literally tells me your business model is in bad shape now and they see it in their books presently. Nobody, other than AWS cancelled their H200's. In fact, Sam Altman just was in a photo with Jensen getting their first H200. The implication here is for all other cloud providers, including sovereign nations, start to worry that they ultimately won't be able to compete on the scale and execution that Open AI and Microsoft have. The answer, to me, is that there is NO way, zero possibility, that the entire world is going to stand there and watch Microsoft and Open AI dominate the AI race. Asia's not going to back down, Europe isn't going to back down, Australia isn't going to back down under. Japan... Well, Japan is going to Open AI so. However, it is clear that AWS flinched and they're in trouble. While their cloud business may be fine right at this moment how long can them not having a frontier model start materially hurting their cloud business overall? Also, Microsoft's revenues are larger than many countries GDP. How much can the world really throw at sovereign AI in earnest when they don't even have the capacity to really compete financially if AWS can't even do it? Apple, has already capitulated and is probably going with OpenAI for their AI needs. Sora stopped a movie production studio from ever happening. Is this a consolidation of the AI power? Nvidia, must prove this quarter that this not the case. Those digital twins and DGX cloud systems need to show that there is great use. Meaning, I want to hear an analyst ask this question. What is the usage of the DGX cloud that is being provided by the major cloud companies and rest of world overall. Meaning, are people using DGX cloud offerings that are licensed and provided in the major cloud vendors. Apparently, not really for AWS. But that analysis is very important for how Nvidia data centers go. Yes, GPT/LLM's are one thing but all of other AI being done X GPT/LLM's and inference needs to be the lion share of the growth for Nvidia to keep powering forward. 2. What percentage of AI workload in Nvidia's business is NONE LLM Related. This is a critical question because it would help to understand how much is all of this hype AI shit going on, how much is LLM usage, and how much is other things accelerated compute based that is not hype and or LLM training and usage. Where is the growth coming from? Robotics, protein folding, teenagers in their basement trying to make the next big video game. Where, What, Why and How. Even with the Nvidia offering all of their rock star concert conference offerings they are not going to realize billions from that for some time. I think they beat this quarter and give ok guidance. There will be a slight sell down and it gets picked up and eaten up the following day for a fantastic call heading into Q2025. The only way this stock doesn't go down with all of these headwinds that Nvidia must answer for is if they do a stock split. If they stock split this moons 15% over the week. I have a small position and looking to add more. No Split 9%+ for the week Split 15+ for the week","Great analysis if amazon had actually cancelled orders, hut they havenâ€™t and said so themselves.",0,0.604,0.997,NEGATIVE
,"Nvidia has had the wildest ride these past months and shook out a 10% knife over a month ago. Brutal. On top of all that you have rando's coming out saying they sold some profits off the top and the whole interest rate thing. Let's face it. Besides Google's break out, The Mag 7 has been sideways and hard to trade. Don't get me wrong, these companies have been up but they have also been punched in the mouth a few times. With that said, nothing is more peculiar than what Amazon has just done with the retiring of it's AWS CEO and more recently, their order cancellations of Nvidia's H200's. For me, the 2 things are very linked together. The notion that your massive cloud business has NO USE of H200's is a DAMNING statement. Not for AI, because Microsoft and Open AI are killing it right now, but specifically for Amazon AWS. How do you not have an ultra well-defined blueprint for where those H200's are going to go? The very notion that you would not have a plan to replace older accelerated compute AND OR expand your data centers is astonishing to me. The 2 companies could not be more world's apart in their AI trajectory. I listened to every word out of Satya's mouth on Microsoft's earnings call and the one key question that was asked over and over again was this, ""Why were your profits for AI cloud only 7% gains?"" The response was, ""There is too much demand."" Demand is outstripping supply. I can verify this is 100000% true. The one thing that is occuring with all planned projects out there in this space is the ability to service enmasse enough throughput per use case of AI compute. Now, a lot of that is latency which is improved with GPT upgrades such as GPT-4o. It's faster so you can put more throughput through the pipe and that is much better for everyone's use case and scalability. Moreover, Microsoft per this build event is putting AI everywhere in their product line. The AI is going to be coming out of your ears, nose and mouth. Open AI has invented HER. ScarJo lawsuits aside ""HER"" is here. It maybe version 1.0 but it's HER for sure. It is spectacular. And OpenAI keeps announcing this stuff everytime someone gets a whiff of thinking they are going to release something ""awesome"" for an AI offering. Everyone else is literally and desperately trying to catch up. On one hand, it's an ARM's race with Nvidia holding all the AI bullets. But in this war are there signs of defeat? In the very least there is some retreat. AWS may become the first casualty of the AI Wars. Reporting that they forgo an entire order of H200's makes absolutely no sense. They say they want to wait for the newer chips but that literally tells me your business model is in bad shape now and they see it in their books presently. Nobody, other than AWS cancelled their H200's. In fact, Sam Altman just was in a photo with Jensen getting their first H200. The implication here is for all other cloud providers, including sovereign nations, start to worry that they ultimately won't be able to compete on the scale and execution that Open AI and Microsoft have. The answer, to me, is that there is NO way, zero possibility, that the entire world is going to stand there and watch Microsoft and Open AI dominate the AI race. Asia's not going to back down, Europe isn't going to back down, Australia isn't going to back down under. Japan... Well, Japan is going to Open AI so. However, it is clear that AWS flinched and they're in trouble. While their cloud business may be fine right at this moment how long can them not having a frontier model start materially hurting their cloud business overall? Also, Microsoft's revenues are larger than many countries GDP. How much can the world really throw at sovereign AI in earnest when they don't even have the capacity to really compete financially if AWS can't even do it? Apple, has already capitulated and is probably going with OpenAI for their AI needs. Sora stopped a movie production studio from ever happening. Is this a consolidation of the AI power? Nvidia, must prove this quarter that this not the case. Those digital twins and DGX cloud systems need to show that there is great use. Meaning, I want to hear an analyst ask this question. What is the usage of the DGX cloud that is being provided by the major cloud companies and rest of world overall. Meaning, are people using DGX cloud offerings that are licensed and provided in the major cloud vendors. Apparently, not really for AWS. But that analysis is very important for how Nvidia data centers go. Yes, GPT/LLM's are one thing but all of other AI being done X GPT/LLM's and inference needs to be the lion share of the growth for Nvidia to keep powering forward. 2. What percentage of AI workload in Nvidia's business is NONE LLM Related. This is a critical question because it would help to understand how much is all of this hype AI shit going on, how much is LLM usage, and how much is other things accelerated compute based that is not hype and or LLM training and usage. Where is the growth coming from? Robotics, protein folding, teenagers in their basement trying to make the next big video game. Where, What, Why and How. Even with the Nvidia offering all of their rock star concert conference offerings they are not going to realize billions from that for some time. I think they beat this quarter and give ok guidance. There will be a slight sell down and it gets picked up and eaten up the following day for a fantastic call heading into Q2025. The only way this stock doesn't go down with all of these headwinds that Nvidia must answer for is if they do a stock split. If they stock split this moons 15% over the week. I have a small position and looking to add more. No Split 9%+ for the week Split 15+ for the week","Amazon didnâ€™t actually cancel their orders for anything, it was bad reporting. Theyâ€™ve chosen to buy more expensive chips for the future orders, which is bullish.",0,0.531,1.0,NEGATIVE

date of comment,main comment,comment,depth,PTR Sentiment,Flair Sentiment,Flair Outlook
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",What is going on with this post? Users of WSB is this post interesting to you?,0,0.511,0.999,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",lol wut ?,0,0.5,0.799,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",wut?,1,0.5,0.999,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",What positions ?,2,0.5,0.967,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",Nvidia lol what else. straight up no options. I can't even afford options.,3,0.526,1.0,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",What is going on with this post? Users of WSB is this post interesting to you?,2,0.511,0.999,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",Please delete 1st video - it's terrifying!,0,0.503,1.0,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",lol it is super odd. It's like watching the inside of my brain create thoughts.,1,0.506,0.688,POSITIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.","I am like, keep reading maybe it ll make sense.",0,0.507,0.99,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",Lol tldr. We're just getting started,1,0.513,0.999,POSITIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",Are you ok man?,0,0.502,0.901,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",A OK!,1,0.5,0.909,POSITIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",If you need video to train models its definitely going to be good for GOOG and META long term. Think about how much stored video they have.,0,0.525,0.999,POSITIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",It just blows me away with how much data Google has and OpenAI just keeps eating lunch. It's like they're cooking in separate kitchens,1,0.508,0.965,POSITIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",True ai will follow the bell curve and be worthless in the human like model. The 20% of them that are trash along with the energy cost and time associated with developing them makes them a detriment. Tailored solution models will be decent though.,0,0.53,1.0,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.","Great post, OP!Yann, the chief scientist of AI at Meta and Turing award winner himself is not able to comprehend all different possibilities and applications of AI. Every-time a ground breaking innovation occurs, even the original creators cannot imagine the evolution of the technology thereafter.Now think about UBS guys who have been working on excel valuation models all their life. They are no experts in this field and the so called experts do not always have the whole picture because it is nearly impossible for one individual to front run the collective human imagination.This imagination is being brought to life using NVDA's advanced GPUs and the breakthroughs we had in deep learning over the last few years. There is nothing stopping AI. The genie is out of the bottle.",0,0.525,0.788,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.","Appreciated. If one person reads it im happy.What do you think about the compute needed to power this going forward? I don't think Yann saw SORA coming prior to him making those comments. Hell, I don't think Jansen saw this coming prior to those comments.",1,0.513,0.993,POSITIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.","I don't see any alternative to NVDA at the moment but they need to keep innovating at a good pace to front run the competition and as always execution is the key. Eventually every major tech firm will have their own high performing chips just like AAPL has their own chips on their phones now. But guess what, till that point (which I think is more than 5 years away) NVDA will be in prime position and will be the only chip provider that can assimilate into any architecture.with LLMs we only saw the compute demand needed for text in text out models but SORA and Gemini 1.5 are a different category altogether when we think of compute needs.Another major demand for the compute will soon come from sovereign nations and Jensen is openly advocating that every country should have their data within their own systems and use it to develop applications/agents for their countries. Imagine getting all of a country's local newspaper, social media and multiple other data sources that include spending habits, medical data etc. into a model and what you have is the collective intelligence of that society which can be used across many different fields.It's crazy to think about all possibilities but how do we think we are going to verify the originality of deep fake videos that will be coming out ? When I first heard of NFTs I thought it was a dumb idea and now we have ordinals on chain. What if in the future every social media account is on chain and that's the only possible way in a world full of AI generated content for you to authenticate your content. As I've mentioned earlier there's literally no expert out there that can imagine the possible outcomes from this AI revolution.I believe we are on the verge of a pivotal moment in human history and this shit keeps me up at night.",2,0.518,0.775,POSITIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",NVDA $600P it is.,0,0.502,0.859,POSITIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",this thread gave me sars,0,0.503,1.0,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",Why you always trolling? lol. come on man you know you want to join in the fun.,1,0.51,1.0,POSITIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",Why you always trolling?is this thread not trolling? it's a wall of hyperbole and platitude.,2,0.506,0.999,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.","dude, how do you make investment decisions? Seriously. hyperbole? do you believe that this AI stuff is just a fade. it will pass? Serious question?",3,0.528,1.0,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.","watwait, do you actually think that this thread was some coherent, well-typed dd? or actually contains ANY dd in it, anywhere?Seriously. hyperbole?...do you not know what this word means? because... yes, hyperbole. the post was loaded to the tits in it.ffs, every other comment is mocking it/befuddled/asking if you're ok. lolz.do you believe that this AI stuff is just a fade. it will pass? Serious question?i think most of it is bullshit. eg, amd's and intel's ai announcement with nothing to show. their xdna (and whatever intel called it) demos that failed to work, for windows ai that had no use cases (and still doesn't really seem to have any, unless one just REALLY WANTS BLURRED BACKGROUNDS WHILE STREAMING... enough to buy a new pc for it). i think chatgpt is mostly shit. like, wow, people can still not read their emails. huge change. copilot surely got subs, but i'm skeptical of it lasting.dcai $ is legit.",4,0.533,1.0,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",which part exactly is hyperbole? to you.,5,0.517,0.994,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.","the fact that you're asking which part makes it clear that you not only don't know what the word means, but you're too lazy/willfully ignorant to look it up and you clearly didn't use your chat gpt to tell you (or it failed).your post is like 80% hyperbole. lolz @ asking which part. almost all of it.",6,0.513,1.0,NEGATIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",10 GPU cards per human on Earth to go through TikTok videos. Got it.,0,0.518,1.0,POSITIVE
,"Somehow or another UBS (The same people who upgraded Chargepoint to $7/8 per share right before it crashed) is complaining about a reduced lead times for Nvidia is somehow a bad thing. Let's break this down. So you're trying to convince me a company that had 11+ months of lead time working towards expanding production capacity so that the lead times are cut to 4+ months is somehow doing something wrong? At first glance, wouldn't reduced lead times (by 50%) expect a massive increase in profits for that current quarter because you were effectively doubling your order output from a booked sales POV? As well, why would UBS question this portion of growth when in fact 80%+ of their business is coming from their data center which has nothing to do with booked sales of their product. How are they confabulating lead times with growth when the growth is the data center. Mark Zuckerberg/Meta and others are reporting massive purchases for product because they have the internal capacity to either USE and or RESALE work that comes from these products. The same goes for AWS, Microsoft and Google. Another dumb thing that analyst are repeating is that once you buy these chips you won't need to buy them again. Do you have kids that have gaming pc's? LOL. You only need to ask a gamer standing outside at 4am of BestBuy to understand that in the chip world and GPU world the next specs are EVERYTHING! What you think you could do today with chipset A is nothing you can do next year or 2 with chipset B. Analysts not understanding this simple concept is (seeking alpha) alarming to me. Let's go back to what Jensen said at the WGS. Compute in the past 10 years has increase by a whopping 1,000,000 time. This was his argument for why we won't need $7 trillion going into chip fabs. However, this is him not knowing about OpenAI's SORA. SORA was a literal ""See I ain't fucking around"" mic drop from Sam Altman. When I ask for $7 trillion I am not kidding around. Let me explain this visually for you. The first video is at base compute. The second video is scaling that up by 4x and the third is when you scale up by 32x. Let's be rock solid clear. This isn't just about video's of cute dogs. 0:00 / 0:00 base compute 0:00 / 0:00 4x's 0:00 / 0:00 32x's This is about simulating worlds that AI can basically run around naked in and learn how to go from Adam and Eve to Iron Man in a period of weeks and months. https://openai.com/research/video-generation-models-as-world-simulators Video generation models as world simulators We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world. From a technical point of view what this means is that the more and more compute you throw at these systems the more amazing god level ASI/AGI things they will be able to do. We are talking about real and true intelligence here folks. With all of this news how do you come to the conclusion that demand is slowing? No, we are just getting started. Let me give you another little tidbit of a wild comment (and I really like Yann Lecun) made at the same WGS conference. You can't dream up this much egg on your face within 48/72 hours. At the timestamp (funny we're talking about video here) 17:36 https://youtu.be/rf9jgZYAni8?si=vxoq3sH5xPaH1T76&t=1056 Yann is asked what would be the ""next"" thing to get us to a higher intelligence with AI. Would it be a new algorithm and boom we've unlocked human level intelligence. Yann replies with we need 4 things. He starts by saying, and I agree, we need to be able to train the AI like the way a baby learns going through the ""world"". See above comments for what SORA and OpenAI just did. I love Yann, but funny enough, he didn't know about SORA and literally said we couldn't do this and that he was working on something with not great effect. And then BOOM Sora was released. The important part, although bad timing here, is that what Yann is referring to is correct and OpenAI just did it. Early, Yann makes another mistake that even Jensen from Nvidia made a similar mistake in the same light (and Google). We need more compute and the holy grail of AI is from world simulation building. World simulation building comes from Video and other stimuli input. Video is that next thing. You can't imagine that (or it would be unlikely) text transformers are going to be the same as image, audio and video transformers. It's why OpenAI has Dal-E. Dal-E is generative. They (apparently only OpenAI) knows this is the start of the endgame which is thought/text/language, video, and audio ai agent multimodal capabilities. All this with a world simulation to train the AGI/ASI human level intelligence baby. But here's Yann just not quite getting it by stating, oddly at the same time buying billions of Nvidia GPU's, that compute requirements will become less and less. Love Yann but he's not seeing the forest through the trees. Listen to his conversation here. BTW I really appreciate him plugging ARM here being in everything in the future. Host: How long do you see the demand going for? Will algorithms improve it's a 2 year wait? Yann: Meta and Microsoft and the UAE is buying them all: timestamp 7:00 https://youtu.be/rf9jgZYAni8?si=uWco6GvPqcR1UNjm&t=420 Yann: Chips are being designed that are more efficient. Trained models can run very easily on ARM https://youtu.be/rf9jgZYAni8?si=76eQ8DJej2WIRjIS&t=502 8:30 https://youtu.be/rf9jgZYAni8?si=6BcFK6GPozF4T2yD&t=546 9:06 Yann: pretty soon you'll have neural nets running in everything including micro-controllers (Yea right about micro-controllers but I get his point) instead just think ARM ARM ARM. AI systems in every embedded device. https://youtu.be/rf9jgZYAni8?si=i8fWW3UqdlQTKK-l&t=600 10:00 Point is Yann didn't see the video thing (SORA) coming when he was making any of these comments. If you asked Yann the exact same question next year his answer would change. it's not going to be Neural Network accelerators but more and more compute that is in a power efficient and compact design. Yann unfortunately sees this all ending at Open Source Software. Again, it's NOT. The worlds most powerful AI will be a national security risk and there is NO way on gods green earth that the US government is going to let a god tier AI just be downloadable on github. Who in the hell believes that? Not me. There will be USANet before there is a powerful enough model to disrupt global markets just hitting the streets. In this way I just feel that Yann is not understanding where this is going. Wrapping it all together. I firmly don't think people are understanding the true extent where this is all going. Chip lead times being fulfilled to me simply means Nvidia is going to report more numbers. Chip advancements simply means there will be a strain on new AI capabilities that come in the future that will need more and more compute power. All of that will simply result down to personal devices that will need more and more compute power to operate. It will be as if we got to start the internet boom era all over again. There will be some who wash out as frauds and there will be new players and new industries that will rise like you've never seen before. This 49er gold rush ain't quitting anytime soon.",GPT-REEEE,0,0.5,0.999,NEGATIVE

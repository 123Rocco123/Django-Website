date of comment,main comment,comment,depth,PTR Sentiment,Flair Outlook,Flair Sentiment
,"I haven't seen any update about AMD able to improve their supply issues to improve MI300 cards, nor do I see wide adoption. A few months ago couple ""AI Datacenter"" startups shared stage with AMD about their new offerings with MI300 but some of them have quietly embraced NVDA and abandoned AMD due to poor supply. No good news which highlights how META uses these cards and any performance benefits in training or inference on MI300. Azure and OCI clouds have some regions with few MI300 compute instances but I have not seen any customer success stories using these vs using Nvidia older generation T4, A100 and H100s. State of ROCm is not bad. It's improving and many have written blogs and KB articles on how Llama3 models are running without issues on MI300 cards. I read some articles of using Mistral as well. However, AMD still isn't able to demonstrate end to end solutions. Who feels optimistic about AMD and they able to grab at least 5% of AI market in next 2 to 3 years at this snail pace? What are you expecting from tomorrow's AMD AI event? What, if any, are the grown prospects for AMD in AI era with limited supplies for MI cards?","Time is on AMD's side when it comes to ROCm. CUDA has more compatibility due to its age and support, which means everyone goes to Nvidia for GPGPU compute.I've written some CUDA code for roughly a decade, but I'm new to ROCm and see potential in it, despite it having confusing hardware support and bad documentation. One example is no support for integrated GPUs like the 780M, which AMD should add so developers can actually experiment with ROCm. Then there's the IPUs/NPUs (whatever they're calling them this week) bundled with the newer CPUs, which seldom have support and are borderline wastes of silicon so far.It's a rough start, but I'm certain it will improve as the years go by.",0,0.548,NEGATIVE,0.96
,"I haven't seen any update about AMD able to improve their supply issues to improve MI300 cards, nor do I see wide adoption. A few months ago couple ""AI Datacenter"" startups shared stage with AMD about their new offerings with MI300 but some of them have quietly embraced NVDA and abandoned AMD due to poor supply. No good news which highlights how META uses these cards and any performance benefits in training or inference on MI300. Azure and OCI clouds have some regions with few MI300 compute instances but I have not seen any customer success stories using these vs using Nvidia older generation T4, A100 and H100s. State of ROCm is not bad. It's improving and many have written blogs and KB articles on how Llama3 models are running without issues on MI300 cards. I read some articles of using Mistral as well. However, AMD still isn't able to demonstrate end to end solutions. Who feels optimistic about AMD and they able to grab at least 5% of AI market in next 2 to 3 years at this snail pace? What are you expecting from tomorrow's AMD AI event? What, if any, are the grown prospects for AMD in AI era with limited supplies for MI cards?","5% should be no problem, yet the gap with Blackwell / CUDA seems huge.",0,0.501,NEGATIVE,0.794
,"I haven't seen any update about AMD able to improve their supply issues to improve MI300 cards, nor do I see wide adoption. A few months ago couple ""AI Datacenter"" startups shared stage with AMD about their new offerings with MI300 but some of them have quietly embraced NVDA and abandoned AMD due to poor supply. No good news which highlights how META uses these cards and any performance benefits in training or inference on MI300. Azure and OCI clouds have some regions with few MI300 compute instances but I have not seen any customer success stories using these vs using Nvidia older generation T4, A100 and H100s. State of ROCm is not bad. It's improving and many have written blogs and KB articles on how Llama3 models are running without issues on MI300 cards. I read some articles of using Mistral as well. However, AMD still isn't able to demonstrate end to end solutions. Who feels optimistic about AMD and they able to grab at least 5% of AI market in next 2 to 3 years at this snail pace? What are you expecting from tomorrow's AMD AI event? What, if any, are the grown prospects for AMD in AI era with limited supplies for MI cards?",I doubt it,1,0.5,NEGATIVE,0.975
,"I haven't seen any update about AMD able to improve their supply issues to improve MI300 cards, nor do I see wide adoption. A few months ago couple ""AI Datacenter"" startups shared stage with AMD about their new offerings with MI300 but some of them have quietly embraced NVDA and abandoned AMD due to poor supply. No good news which highlights how META uses these cards and any performance benefits in training or inference on MI300. Azure and OCI clouds have some regions with few MI300 compute instances but I have not seen any customer success stories using these vs using Nvidia older generation T4, A100 and H100s. State of ROCm is not bad. It's improving and many have written blogs and KB articles on how Llama3 models are running without issues on MI300 cards. I read some articles of using Mistral as well. However, AMD still isn't able to demonstrate end to end solutions. Who feels optimistic about AMD and they able to grab at least 5% of AI market in next 2 to 3 years at this snail pace? What are you expecting from tomorrow's AMD AI event? What, if any, are the grown prospects for AMD in AI era with limited supplies for MI cards?","It plays out similar to their consumer gpu market. Nvidia is always ahead of the curve and innovating, and AMD are usually playing catch up with an inferior but still decent product. Expect Nvidia to dominate AI with constantly fresh ideas and innovations. I'm in both but more weighted towards Nvidia, definitely some money to be made by both but AMD will be a slower burn.",0,0.576,POSITIVE,0.849
,"I haven't seen any update about AMD able to improve their supply issues to improve MI300 cards, nor do I see wide adoption. A few months ago couple ""AI Datacenter"" startups shared stage with AMD about their new offerings with MI300 but some of them have quietly embraced NVDA and abandoned AMD due to poor supply. No good news which highlights how META uses these cards and any performance benefits in training or inference on MI300. Azure and OCI clouds have some regions with few MI300 compute instances but I have not seen any customer success stories using these vs using Nvidia older generation T4, A100 and H100s. State of ROCm is not bad. It's improving and many have written blogs and KB articles on how Llama3 models are running without issues on MI300 cards. I read some articles of using Mistral as well. However, AMD still isn't able to demonstrate end to end solutions. Who feels optimistic about AMD and they able to grab at least 5% of AI market in next 2 to 3 years at this snail pace? What are you expecting from tomorrow's AMD AI event? What, if any, are the grown prospects for AMD in AI era with limited supplies for MI cards?","Absolute shit show and it was a NON-EVENT.I would have rather watched AMD stay quite until 2026 and continue with ""Best is yet to come"". No new products, no good roadmap to gain confidence about AI in datacenter growth. Same folks who came last year on stage returned to eat free food and waste time.",0,0.579,NEGATIVE,1.0
,"I haven't seen any update about AMD able to improve their supply issues to improve MI300 cards, nor do I see wide adoption. A few months ago couple ""AI Datacenter"" startups shared stage with AMD about their new offerings with MI300 but some of them have quietly embraced NVDA and abandoned AMD due to poor supply. No good news which highlights how META uses these cards and any performance benefits in training or inference on MI300. Azure and OCI clouds have some regions with few MI300 compute instances but I have not seen any customer success stories using these vs using Nvidia older generation T4, A100 and H100s. State of ROCm is not bad. It's improving and many have written blogs and KB articles on how Llama3 models are running without issues on MI300 cards. I read some articles of using Mistral as well. However, AMD still isn't able to demonstrate end to end solutions. Who feels optimistic about AMD and they able to grab at least 5% of AI market in next 2 to 3 years at this snail pace? What are you expecting from tomorrow's AMD AI event? What, if any, are the grown prospects for AMD in AI era with limited supplies for MI cards?","Facts. They took away some of the hope with lackluster launch of products compared to nvdia. Should have stayed quiet, I totally agree.",1,0.516,NEGATIVE,0.999
,"I haven't seen any update about AMD able to improve their supply issues to improve MI300 cards, nor do I see wide adoption. A few months ago couple ""AI Datacenter"" startups shared stage with AMD about their new offerings with MI300 but some of them have quietly embraced NVDA and abandoned AMD due to poor supply. No good news which highlights how META uses these cards and any performance benefits in training or inference on MI300. Azure and OCI clouds have some regions with few MI300 compute instances but I have not seen any customer success stories using these vs using Nvidia older generation T4, A100 and H100s. State of ROCm is not bad. It's improving and many have written blogs and KB articles on how Llama3 models are running without issues on MI300 cards. I read some articles of using Mistral as well. However, AMD still isn't able to demonstrate end to end solutions. Who feels optimistic about AMD and they able to grab at least 5% of AI market in next 2 to 3 years at this snail pace? What are you expecting from tomorrow's AMD AI event? What, if any, are the grown prospects for AMD in AI era with limited supplies for MI cards?",-5% after event.Simple message they are launching MI355 and META uses MI300 exclusively for inference would have gained lot more trust.,2,0.507,NEGATIVE,0.993
,"I haven't seen any update about AMD able to improve their supply issues to improve MI300 cards, nor do I see wide adoption. A few months ago couple ""AI Datacenter"" startups shared stage with AMD about their new offerings with MI300 but some of them have quietly embraced NVDA and abandoned AMD due to poor supply. No good news which highlights how META uses these cards and any performance benefits in training or inference on MI300. Azure and OCI clouds have some regions with few MI300 compute instances but I have not seen any customer success stories using these vs using Nvidia older generation T4, A100 and H100s. State of ROCm is not bad. It's improving and many have written blogs and KB articles on how Llama3 models are running without issues on MI300 cards. I read some articles of using Mistral as well. However, AMD still isn't able to demonstrate end to end solutions. Who feels optimistic about AMD and they able to grab at least 5% of AI market in next 2 to 3 years at this snail pace? What are you expecting from tomorrow's AMD AI event? What, if any, are the grown prospects for AMD in AI era with limited supplies for MI cards?","I honestly don't know very much about the AI generation. I mean, I'm an engineer, I know more than a layman, but I won't pretend to be an expertthat said, both Nvidia and AMD have always sincerely impressed me, to the point where I have exclusively always run those two together (even despite their previous incompatibilities and audio stuttering issues via PCM, which I was constantly fixing)I am an NVDA holder because they *always* seem to find a way to make themselves the center of the conversation, to make ""aspirational"" parts.I am an AMD lover because they always managed to hold their own against Intel at a fraction of the price. every single time someone said they were dead, they'd come out with something like Phenom II or Ryzen that blew everyone awayessentially, I'll set aside the balance sheet due diligence, as you'll no doubt do that separately...but that ""it factor"" people look for in addition to a solid 10K? AMD has it in its tenacity and unwillingness to give up.I wouldn't be surprised at *all* to see AMD capture a share of the AI market....but remember, even with all Intels massive mistakes, they never managed to *corner* the market, so I also wouldn't expect them to have a massive takeover.maybe that suggests a small position is logical if the balance sheet looks right?",0,0.556,POSITIVE,0.938
,"I haven't seen any update about AMD able to improve their supply issues to improve MI300 cards, nor do I see wide adoption. A few months ago couple ""AI Datacenter"" startups shared stage with AMD about their new offerings with MI300 but some of them have quietly embraced NVDA and abandoned AMD due to poor supply. No good news which highlights how META uses these cards and any performance benefits in training or inference on MI300. Azure and OCI clouds have some regions with few MI300 compute instances but I have not seen any customer success stories using these vs using Nvidia older generation T4, A100 and H100s. State of ROCm is not bad. It's improving and many have written blogs and KB articles on how Llama3 models are running without issues on MI300 cards. I read some articles of using Mistral as well. However, AMD still isn't able to demonstrate end to end solutions. Who feels optimistic about AMD and they able to grab at least 5% of AI market in next 2 to 3 years at this snail pace? What are you expecting from tomorrow's AMD AI event? What, if any, are the grown prospects for AMD in AI era with limited supplies for MI cards?","These events don't mean much.As your post is in r/stocks, I believe your question is more about the stock price. Q3 earnings call - where each number in the balance sheet is vetted by auditors, and CxOs are personally liable for any omission/ misrepresentation, have much more effect on the stock, than anything else. Q3 earnings from others in the semi-gang would also boost the overall sentiment for the sector. So I'd pay more attention to those dates.",0,0.547,NEGATIVE,0.999
,"I haven't seen any update about AMD able to improve their supply issues to improve MI300 cards, nor do I see wide adoption. A few months ago couple ""AI Datacenter"" startups shared stage with AMD about their new offerings with MI300 but some of them have quietly embraced NVDA and abandoned AMD due to poor supply. No good news which highlights how META uses these cards and any performance benefits in training or inference on MI300. Azure and OCI clouds have some regions with few MI300 compute instances but I have not seen any customer success stories using these vs using Nvidia older generation T4, A100 and H100s. State of ROCm is not bad. It's improving and many have written blogs and KB articles on how Llama3 models are running without issues on MI300 cards. I read some articles of using Mistral as well. However, AMD still isn't able to demonstrate end to end solutions. Who feels optimistic about AMD and they able to grab at least 5% of AI market in next 2 to 3 years at this snail pace? What are you expecting from tomorrow's AMD AI event? What, if any, are the grown prospects for AMD in AI era with limited supplies for MI cards?",-4% :D,1,0.53,POSITIVE,0.963
